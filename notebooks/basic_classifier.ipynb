{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1094c3c6-2f22-472d-aeca-3f94b742a549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/data3/junibg-ego/Modelo_leo_coi\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bea7ca3-7804-474c-a3d4-1489c925a1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿GPU disponible? True\n",
      "Número de GPUs: 2\n",
      "Nombre GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"¿GPU disponible? {torch.cuda.is_available()}\")\n",
    "print(f\"Número de GPUs: {torch.cuda.device_count()}\")\n",
    "print(f\"Nombre GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49aa6170-2f16-47bf-9ed1-2eca29f87e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e41276dc-8cbe-4305-b3ed-c57badbee5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.load_fastaDataset import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b61594b-2dcb-4bfe-b63e-8e8307166e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hierarchy_from_json(json_path):\n",
    "    \"\"\"Carga la jerarquía taxonómica desde JSON\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        hierarchy_raw = json.load(f)\n",
    "    \n",
    "    # Convertir claves string a int\n",
    "    hierarchy = {}\n",
    "    for child_taxon, parent_dict in hierarchy_raw.items():\n",
    "        hierarchy[child_taxon] = {}\n",
    "        for parent_key, children_list in parent_dict.items():\n",
    "            parent_int = int(float(parent_key))\n",
    "            children_int = [int(c) for c in children_list]\n",
    "            hierarchy[child_taxon][parent_int] = children_int\n",
    "    \n",
    "    print(\"✅ Jerarquía cargada desde JSON\")\n",
    "    for taxon, mapping in hierarchy.items():\n",
    "        n_parents = len(mapping)\n",
    "        n_children = sum(len(v) for v in mapping.values())\n",
    "        print(f\"  {taxon:10s}: {n_parents:4d} padres → {n_children:5d} hijos\")\n",
    "    \n",
    "    return hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8522d134-ccfb-4531-9c27-12b9b3a30c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Jerarquía cargada desde JSON\n",
      "  class     :   49 padres →   187 hijos\n",
      "  order     :  173 padres →   831 hijos\n",
      "  family    :  797 padres →  5446 hijos\n",
      "  genus     : 5393 padres → 50568 hijos\n",
      "  species   : 50510 padres → 205075 hijos\n"
     ]
    }
   ],
   "source": [
    "hierarchy_path = os.path.join(project_root, \"src\", \"data\", \"taxonomy_hierarchy_fixed_with_class.json\")\n",
    "hierarchy = load_hierarchy_from_json(hierarchy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13bdbd12-7690-4119-9ff7-c3010517aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = os.path.join(project_root, \"src\", \"data\", \"all_taxa_numeric.csv\")\n",
    "df = pd.read_csv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f15e5c6-57db-4a48-a06d-ae980f9fe31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  phylum    :     49 clases\n",
      "  class     :    173 clases\n",
      "  order     :    797 clases\n",
      "  family    :   5393 clases\n",
      "  genus     :  50510 clases\n",
      "  species   : 205075 clases\n"
     ]
    }
   ],
   "source": [
    "taxon_order = ['phylum', 'class','order', 'family', 'genus', 'species']\n",
    "total_classes = {}\n",
    "for taxon in taxon_order:\n",
    "    n_classes = df[taxon].nunique()\n",
    "    total_classes[taxon] = n_classes\n",
    "    print(f\"  {taxon:10s}: {n_classes:6d} clases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c4046f-8747-46a0-998d-dbb40d8cb7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 173, 797, 5393, 50510, 205075]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /data/data3/junibg-ego/Modelo_leo_coi/src/data/archives and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNAClassifier(\n",
      "  (embedder): DNABERTEmbedder(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(4096, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x BertLayer(\n",
      "            (attention): BertUnpadAttention(\n",
      "              (self): BertUnpadSelfAttention(\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (mlp): BertGatedLinearUnitMLP(\n",
      "              (gated_layers): Linear(in_features=768, out_features=6144, bias=False)\n",
      "              (act): GELU(approximate='none')\n",
      "              (wo): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (rank_classifiers_pre_process): ModuleList(\n",
      "    (0-5): 6 x Sequential(\n",
      "      (0): ResBlock(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (conv1): Conv1d(1, 768, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (bn2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(768, 1, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (rank_classifiers_end): ModuleList(\n",
      "    (0-5): 6 x Sequential(\n",
      "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (1): RankClassiferCosine(\n",
      "        (classifier): Sequential(\n",
      "          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "          (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (5): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (6): GELU(approximate='none')\n",
      "          (7): Dropout(p=0.1, inplace=False)\n",
      "          (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (9): CosineClassifier()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from src.basic_classifier.build_classifier import *\n",
    "\n",
    "number_of_classes = []\n",
    "for class_name, num_classes in total_classes.items():\n",
    "    number_of_classes.append(num_classes)\n",
    "\n",
    "print(number_of_classes)\n",
    "\n",
    "model_configuration = get_model_config(number_of_classes, project_root)\n",
    "classifier = build_model(model_configuration)\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef7c3f49-dd3c-4dce-bcb9-92d6237903ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Primero separar test (20%)\n",
    "df_temp, df_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['phylum']\n",
    ")\n",
    "\n",
    "# Luego separar train/val (80/20 del 80% restante = 64/16 del total)\n",
    "df_train, df_val = train_test_split(\n",
    "    df_temp, test_size=0.2, random_state=42, stratify=df_temp['phylum']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "546e9631-fa9b-4928-a98c-40d8edee91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = MultiTaxaFastaDataset(\n",
    "    df_val.reset_index(drop=True),\n",
    "    max_length=750,\n",
    "    taxon_cols=taxon_order\n",
    ")\n",
    "\n",
    "training_dataset = MultiTaxaFastaDataset(\n",
    "    df_train.reset_index(drop=True),\n",
    "    max_length=750,\n",
    "    taxon_cols=taxon_order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "752e4196-d15b-4e0d-9cf8-9d369e235fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_multitask(batch, taxon_cols=['phylum', 'class','order','family','genus','species'], max_length=900):\n",
    "    sequences, labels_dict_list, recon_targets_list, true_tokens_list = zip(*batch)\n",
    "\n",
    "    # Labels: dict de tensors\n",
    "    labels_dict = {taxon: torch.stack([d[taxon] for d in labels_dict_list]) for taxon in taxon_cols}\n",
    "\n",
    "    # Recon targets: dict de tensors\n",
    "    recon_targets_dict = {taxon: torch.stack([d[taxon] for d in recon_targets_list]) for taxon in taxon_cols}\n",
    "\n",
    "    # True tokens\n",
    "    true_tokens = torch.stack(true_tokens_list)\n",
    "\n",
    "    return sequences, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "959f2e1d-c95b-4ff1-88d8-c641d0326391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.basic_classifier.train_classifier import train_basic_classifier\n",
    "\n",
    "training_config = {\n",
    "        \"batch_size\" : 16,\n",
    "        \"num_epochs\" : 15,\n",
    "        \"lr\" : 5e-4,\n",
    "        \"weight_decay\": 1e-4,  # Add regularization\n",
    "        \"patience\": 5,  # More patience for large class counts\n",
    "        \"label_smoothing\": 0.08,  # Add for better generalization\n",
    "        \"gradient_clip\": 1.0,  # Prevent gradient explosion\n",
    "        \"warmup_epochs\": 2,  # Gradual LR warmup\n",
    "        \"lr_schedule\": \"cosine\",  # Cosine annealing\n",
    "        \"accumulation_steps\": 2,  # Gradient accumulation for effective batch_size=128\n",
    "    }\n",
    "\n",
    "# Optimizer config\n",
    "optimizer_config = {\n",
    "    \"type\": \"AdamW\",\n",
    "    \"lr\": 5e-4,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"eps\": 1e-8\n",
    "}   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a90a5ac-8726-4fe3-9235-ef57f3cf026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=training_config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    collate_fn=lambda b: collate_multitask(b, taxon_cols=val_dataset.taxon_cols, max_length=val_dataset.max_length),\n",
    "    num_workers=6\n",
    ")\n",
    "\n",
    "training_loader = DataLoader(\n",
    "    training_dataset,\n",
    "    batch_size=training_config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=lambda b: collate_multitask(b, taxon_cols=val_dataset.taxon_cols, max_length=val_dataset.max_length),\n",
    "    num_workers=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c2bafdf-cda2-4365-b755-c76a422ed73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Starting training...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [1.79589007e-05 3.83539854e-05 8.83349634e-05 1.50031834e-04\n",
      " 1.79388933e-04 2.09834762e-04]\n",
      "          Top-1: 0.2604, Top-5: 0.3542\n",
      "          Rank Top-1: [0.875  0.625  0.0625 0.     0.     0.    ], Rank Top-5: [1.     0.8125 0.3125 0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0027, Rank Loss: [7.91587271e-05 1.98339328e-04 3.18713974e-04 5.65789625e-04\n",
      " 7.25041936e-04 8.38722261e-04]\n",
      "          Top-1: 0.2083, Top-5: 0.3125\n",
      "          Rank Top-1: [0.875 0.375 0.    0.    0.    0.   ], Rank Top-5: [0.9375 0.5625 0.375  0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [3.05824331e-05 4.86370737e-05 8.49233240e-05 1.39326245e-04\n",
      " 1.77836611e-04 2.01813725e-04]\n",
      "          Top-1: 0.1979, Top-5: 0.3125\n",
      "          Rank Top-1: [0.5625 0.4375 0.125  0.0625 0.     0.    ], Rank Top-5: [0.875  0.5625 0.375  0.0625 0.     0.    ]\n",
      "  Val   - Loss: 0.0028, Rank Loss: [8.21138748e-05 2.13151149e-04 3.21504297e-04 5.68163283e-04\n",
      " 7.27218993e-04 8.38535725e-04]\n",
      "          Top-1: 0.1771, Top-5: 0.3125\n",
      "          Rank Top-1: [0.75   0.25   0.0625 0.     0.     0.    ], Rank Top-5: [0.9375 0.5625 0.375  0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [2.49456977e-05 3.92645530e-05 7.61268362e-05 1.41119424e-04\n",
      " 1.90813405e-04 2.08163655e-04]\n",
      "          Top-1: 0.2396, Top-5: 0.3750\n",
      "          Rank Top-1: [0.8125 0.625  0.     0.     0.     0.    ], Rank Top-5: [0.875  0.8125 0.5625 0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0027, Rank Loss: [8.45942693e-05 1.97569997e-04 3.14870348e-04 5.73680516e-04\n",
      " 7.32125492e-04 8.40759030e-04]\n",
      "          Top-1: 0.2083, Top-5: 0.3333\n",
      "          Rank Top-1: [0.75  0.375 0.125 0.    0.    0.   ], Rank Top-5: [0.9375 0.625  0.375  0.0625 0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [1.42007082e-05 2.66235212e-05 7.42678736e-05 1.39052214e-04\n",
      " 1.87379822e-04 2.17331633e-04]\n",
      "          Top-1: 0.2917, Top-5: 0.4375\n",
      "          Rank Top-1: [0.875 0.625 0.25  0.    0.    0.   ], Rank Top-5: [1.     1.     0.5625 0.0625 0.     0.    ]\n",
      "  Val   - Loss: 0.0028, Rank Loss: [8.79814108e-05 2.04779794e-04 3.29153327e-04 5.76729866e-04\n",
      " 7.32518323e-04 8.40266417e-04]\n",
      "          Top-1: 0.2188, Top-5: 0.3229\n",
      "          Rank Top-1: [0.75   0.375  0.1875 0.     0.     0.    ], Rank Top-5: [0.9375 0.625  0.375  0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [2.74613283e-05 2.90454727e-05 8.33029730e-05 1.43700690e-04\n",
      " 1.88531517e-04 2.09965695e-04]\n",
      "          Top-1: 0.2708, Top-5: 0.3542\n",
      "          Rank Top-1: [0.75  0.75  0.125 0.    0.    0.   ], Rank Top-5: [0.875 0.875 0.375 0.    0.    0.   ]\n",
      "  Val   - Loss: 0.0028, Rank Loss: [8.47112249e-05 2.14257029e-04 3.26659510e-04 5.80677873e-04\n",
      " 7.34613257e-04 8.39722616e-04]\n",
      "          Top-1: 0.2292, Top-5: 0.3333\n",
      "          Rank Top-1: [0.8125 0.375  0.1875 0.     0.     0.    ], Rank Top-5: [0.9375 0.6875 0.375  0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [1.55205208e-05 3.80071478e-05 7.20571028e-05 1.41211149e-04\n",
      " 1.97285886e-04 2.10512074e-04]\n",
      "          Top-1: 0.2500, Top-5: 0.3958\n",
      "          Rank Top-1: [0.8125 0.5625 0.125  0.     0.     0.    ], Rank Top-5: [1.     0.9375 0.4375 0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0027, Rank Loss: [7.28844902e-05 1.86223172e-04 3.17338355e-04 5.85013958e-04\n",
      " 7.36033056e-04 8.38990488e-04]\n",
      "          Top-1: 0.2500, Top-5: 0.3438\n",
      "          Rank Top-1: [0.875  0.4375 0.1875 0.     0.     0.    ], Rank Top-5: [1.     0.6875 0.375  0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/15]\n",
      "  Train - Loss: 0.0006, Rank Loss: [1.93255393e-05 3.09778557e-05 6.92960320e-05 1.34740705e-04\n",
      " 1.91935246e-04 2.03231115e-04]\n",
      "          Top-1: 0.2500, Top-5: 0.4167\n",
      "          Rank Top-1: [0.75   0.6875 0.0625 0.     0.     0.    ], Rank Top-5: [1.     0.8125 0.6875 0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0027, Rank Loss: [6.80433272e-05 1.86582351e-04 3.23060710e-04 5.87913387e-04\n",
      " 7.36026202e-04 8.38929482e-04]\n",
      "          Top-1: 0.2708, Top-5: 0.3542\n",
      "          Rank Top-1: [0.875  0.5625 0.1875 0.     0.     0.    ], Rank Top-5: [1.    0.75  0.375 0.    0.    0.   ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [1.75532341e-05 4.27429133e-05 7.60178691e-05 1.32682926e-04\n",
      " 1.88760149e-04 2.17791706e-04]\n",
      "          Top-1: 0.2708, Top-5: 0.3854\n",
      "          Rank Top-1: [0.8125 0.625  0.1875 0.     0.     0.    ], Rank Top-5: [1.     0.75   0.5625 0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0027, Rank Loss: [6.65162442e-05 1.85500429e-04 3.25317636e-04 5.88584139e-04\n",
      " 7.36173961e-04 8.37967225e-04]\n",
      "          Top-1: 0.2708, Top-5: 0.3542\n",
      "          Rank Top-1: [0.9375 0.5625 0.125  0.     0.     0.    ], Rank Top-5: [1.    0.75  0.375 0.    0.    0.   ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [1.46225920e-05 2.67854455e-05 6.56646291e-05 1.42890282e-04\n",
      " 1.91066365e-04 2.09815574e-04]\n",
      "          Top-1: 0.3438, Top-5: 0.4375\n",
      "          Rank Top-1: [0.9375 0.8125 0.3125 0.     0.     0.    ], Rank Top-5: [1.     0.9375 0.6875 0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0027, Rank Loss: [6.27414005e-05 1.80701462e-04 3.27962639e-04 5.88425080e-04\n",
      " 7.36072512e-04 8.37133895e-04]\n",
      "          Top-1: 0.2708, Top-5: 0.3438\n",
      "          Rank Top-1: [0.875  0.5625 0.1875 0.     0.     0.    ], Rank Top-5: [1.     0.6875 0.375  0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10/15]\n",
      "  Train - Loss: 0.0006, Rank Loss: [1.24921919e-05 3.15612942e-05 6.90698006e-05 1.41899992e-04\n",
      " 1.83815306e-04 2.08376711e-04]\n",
      "          Top-1: 0.3438, Top-5: 0.4167\n",
      "          Rank Top-1: [1.     0.8125 0.25   0.     0.     0.    ], Rank Top-5: [1.     0.9375 0.5625 0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0027, Rank Loss: [6.34402625e-05 1.79976312e-04 3.28779853e-04 5.87065855e-04\n",
      " 7.36351915e-04 8.37634535e-04]\n",
      "          Top-1: 0.2292, Top-5: 0.3438\n",
      "          Rank Top-1: [0.8125 0.5    0.0625 0.     0.     0.    ], Rank Top-5: [1.     0.6875 0.375  0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [11/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [1.45231801e-05 3.11304003e-05 7.86815272e-05 1.37024645e-04\n",
      " 1.88049617e-04 2.19487341e-04]\n",
      "          Top-1: 0.2708, Top-5: 0.3854\n",
      "          Rank Top-1: [0.875 0.625 0.125 0.    0.    0.   ], Rank Top-5: [1.     0.875  0.4375 0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0027, Rank Loss: [6.32240688e-05 1.75668631e-04 3.29746093e-04 5.86895620e-04\n",
      " 7.37180676e-04 8.37857563e-04]\n",
      "          Top-1: 0.2292, Top-5: 0.3438\n",
      "          Rank Top-1: [0.875  0.4375 0.0625 0.     0.     0.    ], Rank Top-5: [1.     0.6875 0.375  0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [12/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [1.44774771e-05 3.56658449e-05 7.16520768e-05 1.38074999e-04\n",
      " 1.81426242e-04 2.19491185e-04]\n",
      "          Top-1: 0.2917, Top-5: 0.3854\n",
      "          Rank Top-1: [0.875  0.6875 0.125  0.0625 0.     0.    ], Rank Top-5: [1.     0.8125 0.4375 0.0625 0.     0.    ]\n",
      "  Val   - Loss: 0.0027, Rank Loss: [6.32612055e-05 1.76654166e-04 3.29262711e-04 5.86870551e-04\n",
      " 7.37366039e-04 8.38729547e-04]\n",
      "          Top-1: 0.2292, Top-5: 0.3438\n",
      "          Rank Top-1: [0.875  0.4375 0.0625 0.     0.     0.    ], Rank Top-5: [1.     0.6875 0.375  0.     0.     0.    ]\n",
      "Early stopping.\n",
      "\n",
      "BEST MODEL\n",
      "  Train - Loss: 0.0006, Rank Loss: [1.93255393e-05 3.09778557e-05 6.92960320e-05 1.34740705e-04\n",
      " 1.91935246e-04 2.03231115e-04]\n",
      "          Top-1: 0.2500, Top-5: 0.4167\n",
      "          Rank Top-1: [0.75   0.6875 0.0625 0.     0.     0.    ], Rank Top-5: [1.     0.8125 0.6875 0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0027, Rank Loss: [6.80433272e-05 1.86582351e-04 3.23060710e-04 5.87913387e-04\n",
      " 7.36026202e-04 8.38929482e-04]\n",
      "          Top-1: 0.2708, Top-5: 0.3542\n",
      "          Rank Top-1: [0.875  0.5625 0.1875 0.     0.     0.    ], Rank Top-5: [1.    0.75  0.375 0.    0.    0.   ]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "classifier.to(\"cuda\")\n",
    "\n",
    "max_length = model_configuration[\"config_embedder\"][\"max_length\"]\n",
    "best_val_acc, best_model_state, history, last_improved = train_basic_classifier(classifier, training_loader, val_loader, training_config, optimizer_config)\n",
    "\n",
    "date = datetime.now().strftime(\"%Y%m%d\")\n",
    "torch.save(best_model_state, f\"best_model_ddp_{date}.pt\")\n",
    "\n",
    "best_model_train_metrics = history[\"train\"][last_improved]\n",
    "best_model_val_metrics = history[\"val\"][last_improved]\n",
    "\n",
    "print(\"\\nBEST MODEL\")\n",
    "print(f\"  Train - Loss: {best_model_train_metrics['loss_avg']:.4f}, Rank Loss: {best_model_train_metrics['loss_rank_avg']}\")\n",
    "print(f\"          Top-1: {best_model_train_metrics['top1_acc']:.4f}, Top-5: {best_model_train_metrics['top5_acc']:.4f}\")\n",
    "print(f\"          Rank Top-1: {best_model_train_metrics['top1_rank_acc']}, Rank Top-5: {best_model_train_metrics['top5_rank_acc']}\")\n",
    "print(f\"  Val   - Loss: {best_model_val_metrics['loss_avg']:.4f}, Rank Loss: {best_model_val_metrics['loss_rank_avg']}\")\n",
    "print(f\"          Top-1: {best_model_val_metrics['top1_acc']:.4f}, Top-5: {best_model_val_metrics['top5_acc']:.4f}\")\n",
    "print(f\"          Rank Top-1: {best_model_val_metrics['top1_rank_acc']}, Rank Top-5: {best_model_val_metrics['top5_rank_acc']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch Env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
