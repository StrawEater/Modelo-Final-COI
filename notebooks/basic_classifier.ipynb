{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1094c3c6-2f22-472d-aeca-3f94b742a549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/data3/junibg-ego/Modelo_leo_coi\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bea7ca3-7804-474c-a3d4-1489c925a1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿GPU disponible? True\n",
      "Número de GPUs: 2\n",
      "Nombre GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"¿GPU disponible? {torch.cuda.is_available()}\")\n",
    "print(f\"Número de GPUs: {torch.cuda.device_count()}\")\n",
    "print(f\"Nombre GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49aa6170-2f16-47bf-9ed1-2eca29f87e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e41276dc-8cbe-4305-b3ed-c57badbee5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.load_fastaDataset import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b61594b-2dcb-4bfe-b63e-8e8307166e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hierarchy_from_json(json_path):\n",
    "    \"\"\"Carga la jerarquía taxonómica desde JSON\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        hierarchy_raw = json.load(f)\n",
    "    \n",
    "    # Convertir claves string a int\n",
    "    hierarchy = {}\n",
    "    for child_taxon, parent_dict in hierarchy_raw.items():\n",
    "        hierarchy[child_taxon] = {}\n",
    "        for parent_key, children_list in parent_dict.items():\n",
    "            parent_int = int(float(parent_key))\n",
    "            children_int = [int(c) for c in children_list]\n",
    "            hierarchy[child_taxon][parent_int] = children_int\n",
    "    \n",
    "    print(\"✅ Jerarquía cargada desde JSON\")\n",
    "    for taxon, mapping in hierarchy.items():\n",
    "        n_parents = len(mapping)\n",
    "        n_children = sum(len(v) for v in mapping.values())\n",
    "        print(f\"  {taxon:10s}: {n_parents:4d} padres → {n_children:5d} hijos\")\n",
    "    \n",
    "    return hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8522d134-ccfb-4531-9c27-12b9b3a30c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Jerarquía cargada desde JSON\n",
      "  class     :   49 padres →   187 hijos\n",
      "  order     :  173 padres →   831 hijos\n",
      "  family    :  797 padres →  5446 hijos\n",
      "  genus     : 5393 padres → 50568 hijos\n",
      "  species   : 50510 padres → 205075 hijos\n"
     ]
    }
   ],
   "source": [
    "hierarchy_path = os.path.join(project_root, \"src\", \"data\", \"taxonomy_hierarchy_fixed_with_class.json\")\n",
    "hierarchy = load_hierarchy_from_json(hierarchy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13bdbd12-7690-4119-9ff7-c3010517aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = os.path.join(project_root, \"src\", \"data\", \"all_taxa_numeric.csv\")\n",
    "df = pd.read_csv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f15e5c6-57db-4a48-a06d-ae980f9fe31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  phylum    :     49 clases\n",
      "  class     :    173 clases\n",
      "  order     :    797 clases\n",
      "  family    :   5393 clases\n",
      "  genus     :  50510 clases\n",
      "  species   : 205075 clases\n"
     ]
    }
   ],
   "source": [
    "taxon_order = ['phylum', 'class','order', 'family', 'genus', 'species']\n",
    "total_classes = {}\n",
    "for taxon in taxon_order:\n",
    "    n_classes = df[taxon].nunique()\n",
    "    total_classes[taxon] = n_classes\n",
    "    print(f\"  {taxon:10s}: {n_classes:6d} clases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c4046f-8747-46a0-998d-dbb40d8cb7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 173, 797, 5393, 50510, 205075]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /data/data3/junibg-ego/Modelo_leo_coi/src/data/archives and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNAClassifier(\n",
      "  (embedder): DNABERTEmbedder(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(4096, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x BertLayer(\n",
      "            (attention): BertUnpadAttention(\n",
      "              (self): BertUnpadSelfAttention(\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (mlp): BertGatedLinearUnitMLP(\n",
      "              (gated_layers): Linear(in_features=768, out_features=6144, bias=False)\n",
      "              (act): GELU(approximate='none')\n",
      "              (wo): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (rank_classifiers_pre_process): ModuleList(\n",
      "    (0-5): 6 x Sequential(\n",
      "      (0): ResBlock(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (conv1): Conv1d(1, 768, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (bn2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(768, 1, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (rank_classifiers_end): ModuleList(\n",
      "    (0-5): 6 x Sequential(\n",
      "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (1): RankClassiferCosine(\n",
      "        (classifier): Sequential(\n",
      "          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "          (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (5): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (6): GELU(approximate='none')\n",
      "          (7): Dropout(p=0.1, inplace=False)\n",
      "          (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (9): CosineClassifier()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from src.basic_classifier.build_classifier import *\n",
    "\n",
    "number_of_classes = []\n",
    "for class_name, num_classes in total_classes.items():\n",
    "    number_of_classes.append(num_classes)\n",
    "\n",
    "print(number_of_classes)\n",
    "\n",
    "model_configuration = get_model_config(number_of_classes, project_root)\n",
    "classifier = build_model(model_configuration)\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef7c3f49-dd3c-4dce-bcb9-92d6237903ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Primero separar test (20%)\n",
    "df_temp, df_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['phylum']\n",
    ")\n",
    "\n",
    "# Luego separar train/val (80/20 del 80% restante = 64/16 del total)\n",
    "df_train, df_val = train_test_split(\n",
    "    df_temp, test_size=0.2, random_state=42, stratify=df_temp['phylum']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "546e9631-fa9b-4928-a98c-40d8edee91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = MultiTaxaFastaDataset(\n",
    "    df_val.reset_index(drop=True),\n",
    "    max_length=750,\n",
    "    taxon_cols=taxon_order\n",
    ")\n",
    "\n",
    "training_dataset = MultiTaxaFastaDataset(\n",
    "    df_train.reset_index(drop=True),\n",
    "    max_length=750,\n",
    "    taxon_cols=taxon_order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "752e4196-d15b-4e0d-9cf8-9d369e235fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_multitask(batch, taxon_cols=['phylum', 'class','order','family','genus','species'], max_length=900):\n",
    "    sequences, labels_dict_list, recon_targets_list, true_tokens_list = zip(*batch)\n",
    "\n",
    "    # Labels: dict de tensors\n",
    "    labels_dict = {taxon: torch.stack([d[taxon] for d in labels_dict_list]) for taxon in taxon_cols}\n",
    "\n",
    "    # Recon targets: dict de tensors\n",
    "    recon_targets_dict = {taxon: torch.stack([d[taxon] for d in recon_targets_list]) for taxon in taxon_cols}\n",
    "\n",
    "    # True tokens\n",
    "    true_tokens = torch.stack(true_tokens_list)\n",
    "\n",
    "    return sequences, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "959f2e1d-c95b-4ff1-88d8-c641d0326391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.basic_classifier.train_classifier import train_basic_classifier\n",
    "\n",
    "training_config = {\n",
    "        \"batch_size\" : 16,\n",
    "        \"num_epochs\" : 15,\n",
    "        \"lr\" : 5e-4,\n",
    "        \"weight_decay\": 1e-4,  # Add regularization\n",
    "        \"patience\": 5,  # More patience for large class counts\n",
    "        \"label_smoothing\": 0.08,  # Add for better generalization\n",
    "        \"gradient_clip\": 1.0,  # Prevent gradient explosion\n",
    "        \"warmup_epochs\": 2,  # Gradual LR warmup\n",
    "        \"lr_schedule\": \"cosine\",  # Cosine annealing\n",
    "        \"accumulation_steps\": 2,  # Gradient accumulation for effective batch_size=128\n",
    "    }\n",
    "\n",
    "# Optimizer config\n",
    "optimizer_config = {\n",
    "    \"type\": \"AdamW\",\n",
    "    \"lr\": 5e-4,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"eps\": 1e-8\n",
    "}   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a90a5ac-8726-4fe3-9235-ef57f3cf026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=training_config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    collate_fn=lambda b: collate_multitask(b, taxon_cols=val_dataset.taxon_cols, max_length=val_dataset.max_length),\n",
    "    num_workers=6\n",
    ")\n",
    "\n",
    "training_loader = DataLoader(\n",
    "    training_dataset,\n",
    "    batch_size=training_config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=lambda b: collate_multitask(b, taxon_cols=val_dataset.taxon_cols, max_length=val_dataset.max_length),\n",
    "    num_workers=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2bafdf-cda2-4365-b755-c76a422ed73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Starting training...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "max_length = model_configuration[\"config_embedder\"][\"max_length\"]\n",
    "best_val_acc, best_model_state, history, last_improved = train_basic_classifier(classifier, training_loader, val_loader, training_config, optimizer_config)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch Env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
