{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1094c3c6-2f22-472d-aeca-3f94b742a549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/data3/junibg-ego/Modelo_leo_coi\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bea7ca3-7804-474c-a3d4-1489c925a1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿GPU disponible? True\n",
      "Número de GPUs: 2\n",
      "Nombre GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"¿GPU disponible? {torch.cuda.is_available()}\")\n",
    "print(f\"Número de GPUs: {torch.cuda.device_count()}\")\n",
    "print(f\"Nombre GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49aa6170-2f16-47bf-9ed1-2eca29f87e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e41276dc-8cbe-4305-b3ed-c57badbee5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.load_fastaDataset import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b61594b-2dcb-4bfe-b63e-8e8307166e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hierarchy_from_json(json_path):\n",
    "    \"\"\"Carga la jerarquía taxonómica desde JSON\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        hierarchy_raw = json.load(f)\n",
    "    \n",
    "    # Convertir claves string a int\n",
    "    hierarchy = {}\n",
    "    for child_taxon, parent_dict in hierarchy_raw.items():\n",
    "        hierarchy[child_taxon] = {}\n",
    "        for parent_key, children_list in parent_dict.items():\n",
    "            parent_int = int(float(parent_key))\n",
    "            children_int = [int(c) for c in children_list]\n",
    "            hierarchy[child_taxon][parent_int] = children_int\n",
    "    \n",
    "    print(\"✅ Jerarquía cargada desde JSON\")\n",
    "    for taxon, mapping in hierarchy.items():\n",
    "        n_parents = len(mapping)\n",
    "        n_children = sum(len(v) for v in mapping.values())\n",
    "        print(f\"  {taxon:10s}: {n_parents:4d} padres → {n_children:5d} hijos\")\n",
    "    \n",
    "    return hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522d134-ccfb-4531-9c27-12b9b3a30c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy_path = os.path.join(project_root, \"src\", \"data\", \"taxonomy_hierarchy_fixed_with_class.json\")\n",
    "hierarchy = load_hierarchy_from_json(hierarchy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bdbd12-7690-4119-9ff7-c3010517aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = os.path.join(project_root, \"src\", \"data\", \"all_taxa_numeric.csv\")\n",
    "df = pd.read_csv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15e5c6-57db-4a48-a06d-ae980f9fe31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon_order = ['phylum', 'class','order', 'family', 'genus', 'species']\n",
    "total_classes = {}\n",
    "for taxon in taxon_order:\n",
    "    n_classes = df[taxon].nunique()\n",
    "    total_classes[taxon] = n_classes\n",
    "    print(f\"  {taxon:10s}: {n_classes:6d} clases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4046f-8747-46a0-998d-dbb40d8cb7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.basic_classifier.build_classifier import *\n",
    "\n",
    "number_of_classes = []\n",
    "for class_name, num_classes in total_classes.items():\n",
    "    number_of_classes.append(num_classes)\n",
    "\n",
    "print(number_of_classes)\n",
    "\n",
    "model_configuration = get_model_config(number_of_classes, project_root)\n",
    "classifier = build_model(model_configuration)\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c3f49-dd3c-4dce-bcb9-92d6237903ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Primero separar test (20%)\n",
    "df_temp, df_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['phylum']\n",
    ")\n",
    "\n",
    "# Luego separar train/val (80/20 del 80% restante = 64/16 del total)\n",
    "df_train, df_val = train_test_split(\n",
    "    df_temp, test_size=0.2, random_state=42, stratify=df_temp['phylum']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e9631-fa9b-4928-a98c-40d8edee91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = MultiTaxaFastaDataset(\n",
    "    df_val.reset_index(drop=True),\n",
    "    max_length=750,\n",
    "    taxon_cols=taxon_order\n",
    ")\n",
    "\n",
    "training_dataset = MultiTaxaFastaDataset(\n",
    "    df_train.reset_index(drop=True),\n",
    "    max_length=750,\n",
    "    taxon_cols=taxon_order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e4196-d15b-4e0d-9cf8-9d369e235fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_multitask(batch, taxon_cols=['phylum', 'class','order','family','genus','species'], max_length=900):\n",
    "    sequences, labels_dict_list, recon_targets_list, true_tokens_list = zip(*batch)\n",
    "\n",
    "    # Labels: dict de tensors\n",
    "    labels_dict = {taxon: torch.stack([d[taxon] for d in labels_dict_list]) for taxon in taxon_cols}\n",
    "\n",
    "    # Recon targets: dict de tensors\n",
    "    recon_targets_dict = {taxon: torch.stack([d[taxon] for d in recon_targets_list]) for taxon in taxon_cols}\n",
    "\n",
    "    # True tokens\n",
    "    true_tokens = torch.stack(true_tokens_list)\n",
    "\n",
    "    return sequences, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f2e1d-c95b-4ff1-88d8-c641d0326391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.basic_classifier.train_classifier import train_basic_classifier\n",
    "\n",
    "training_config = {\n",
    "        \"batch_size\" : 16,\n",
    "        \"num_epochs\" : 15,\n",
    "        \"lr\" : 5e-4,\n",
    "        \"weight_decay\": 1e-4,  # Add regularization\n",
    "        \"patience\": 5,  # More patience for large class counts\n",
    "        \"label_smoothing\": 0.08,  # Add for better generalization\n",
    "        \"gradient_clip\": 1.0,  # Prevent gradient explosion\n",
    "        \"warmup_epochs\": 2,  # Gradual LR warmup\n",
    "        \"lr_schedule\": \"cosine\",  # Cosine annealing\n",
    "        \"accumulation_steps\": 2,  # Gradient accumulation for effective batch_size=128\n",
    "    }\n",
    "\n",
    "# Optimizer config\n",
    "optimizer_config = {\n",
    "    \"type\": \"AdamW\",\n",
    "    \"lr\": 5e-4,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"eps\": 1e-8\n",
    "}   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90a5ac-8726-4fe3-9235-ef57f3cf026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=training_config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    collate_fn=lambda b: collate_multitask(b, taxon_cols=val_dataset.taxon_cols, max_length=val_dataset.max_length),\n",
    "    num_workers=6\n",
    ")\n",
    "\n",
    "training_loader = DataLoader(\n",
    "    training_dataset,\n",
    "    batch_size=training_config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=lambda b: collate_multitask(b, taxon_cols=val_dataset.taxon_cols, max_length=val_dataset.max_length),\n",
    "    num_workers=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2bafdf-cda2-4365-b755-c76a422ed73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_length = model_configuration[\"config_embedder\"][\"max_length\"]\n",
    "best_val_acc, best_model_state, history, last_improved = train_basic_classifier(classifier, training_loader, val_loader, training_config, optimizer_config)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch Env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
