{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d85016-c144-4477-a84e-893a9ffe5369",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc878647-50d9-4032-9df0-ef5f3a7f393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/data3/junibg-ego/Modelo_leo_coi\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d09de48-c800-4593-934e-35be9e68a25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬øGPU disponible? True\n",
      "N√∫mero de GPUs: 2\n",
      "Nombre GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"¬øGPU disponible? {torch.cuda.is_available()}\")\n",
    "print(f\"N√∫mero de GPUs: {torch.cuda.device_count()}\")\n",
    "print(f\"Nombre GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53085c88-4b09-476c-a880-252cfa5fdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Tus imports\n",
    "from src.combined_model.combined_model_embedding import *\n",
    "from src.combined_model.combined_models import *\n",
    "from src.decoders.decoder_simple import *\n",
    "from src.encoders_model.DNABERT_Embedder import *\n",
    "from src.encoders_model.embdeeding_encoders import *\n",
    "from src.encoders_model.simple_encoders import *\n",
    "from src.evaluators.linear_evaluator import *\n",
    "from src.decoders.sequence_decoder import *\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f6fe74-ed42-42cc-8071-39b1110dee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.encoders_model.simple_encoders import *\n",
    "from src.utils.load_fastaDataset import *\n",
    "from src.training.experimentRunner import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a0540b-2f1b-4835-b2af-af5a0fd105d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hierarchy_from_json(json_path):\n",
    "    \"\"\"Carga la jerarqu√≠a taxon√≥mica desde JSON\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        hierarchy_raw = json.load(f)\n",
    "    \n",
    "    # Convertir claves string a int\n",
    "    hierarchy = {}\n",
    "    for child_taxon, parent_dict in hierarchy_raw.items():\n",
    "        hierarchy[child_taxon] = {}\n",
    "        for parent_key, children_list in parent_dict.items():\n",
    "            parent_int = int(float(parent_key))\n",
    "            children_int = [int(c) for c in children_list]\n",
    "            hierarchy[child_taxon][parent_int] = children_int\n",
    "    \n",
    "    print(\"‚úÖ Jerarqu√≠a cargada desde JSON\")\n",
    "    for taxon, mapping in hierarchy.items():\n",
    "        n_parents = len(mapping)\n",
    "        n_children = sum(len(v) for v in mapping.values())\n",
    "        print(f\"  {taxon:10s}: {n_parents:4d} padres ‚Üí {n_children:5d} hijos\")\n",
    "    \n",
    "    return hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "763948cf-2509-449a-9a3a-7acea1040f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Jerarqu√≠a cargada desde JSON\n",
      "  class     :   49 padres ‚Üí   187 hijos\n",
      "  order     :  173 padres ‚Üí   831 hijos\n",
      "  family    :  797 padres ‚Üí  5446 hijos\n",
      "  genus     : 5393 padres ‚Üí 50568 hijos\n",
      "  species   : 50510 padres ‚Üí 205075 hijos\n"
     ]
    }
   ],
   "source": [
    "hierarchy_path = os.path.join(project_root, \"src\", \"data\", \"taxonomy_hierarchy_fixed_with_class.json\")\n",
    "hierarchy = load_hierarchy_from_json(hierarchy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ea34314-0a7a-4eca-9ccc-b8920d224aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = os.path.join(project_root, \"src\", \"data\", \"all_taxa_numeric.csv\")\n",
    "df = pd.read_csv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc3d09b-ef72-4697-aee2-07c26dd76a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  phylum    :     49 clases\n",
      "  class     :    173 clases\n",
      "  order     :    797 clases\n",
      "  family    :   5393 clases\n",
      "  genus     :  50510 clases\n",
      "  species   : 205075 clases\n"
     ]
    }
   ],
   "source": [
    "taxon_order = ['phylum', 'class','order', 'family', 'genus', 'species']\n",
    "total_classes = {}\n",
    "for taxon in taxon_order:\n",
    "    n_classes = df[taxon].nunique()\n",
    "    total_classes[taxon] = n_classes\n",
    "    print(f\"  {taxon:10s}: {n_classes:6d} clases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208bf5fc-697a-4e59-8a82-71a4bcc4eaa6",
   "metadata": {},
   "source": [
    "# Definimos Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8f3052b-4b55-458b-a11a-ff41b7561ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 750\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861d394-267b-49c7-94bf-154e2f483bb0",
   "metadata": {},
   "source": [
    "# Cargamos el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45ac734b-d0b9-44ed-bb8a-4238e996c93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Dispositivo: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /data/data3/junibg-ego/Modelo_leo_coi/src/data/archives and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creando classifiers con n√∫mero TOTAL de clases:\n",
      "  phylum    :     49 clases\n",
      "  class     :    173 clases\n",
      "  order     :    797 clases\n",
      "  family    :   5393 clases\n",
      "  genus     :  50510 clases\n",
      "  species   : 205075 clases\n",
      "‚úÖ Modelo jer√°rquico creado con m√°scaras suaves (no -inf)\n",
      "\n",
      "‚úÖ Modelo jer√°rquico creado\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üñ•Ô∏è  Dispositivo: {device}\")\n",
    "\n",
    "# DNABERT\n",
    "dnabert_path = os.path.join(project_root, \"src\", \"data\", \"archives\")\n",
    "dnabert = DNABERTEmbedder(\n",
    "    model_name=dnabert_path,\n",
    "    max_length=max_length,\n",
    "    device=device\n",
    ")\n",
    "embed_dim = dnabert.get_embedding_dim()\n",
    "\n",
    "# Encoder\n",
    "latent_dim = 256\n",
    "encoder = SimpleEmbeddingEncoder(\n",
    "    embed_dim=embed_dim,\n",
    "    latent_dim=latent_dim,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# Decoders (uno por tax√≥n)\n",
    "decoders_dict = {}\n",
    "for taxon in taxon_order:\n",
    "    decoders_dict[taxon] = SequenceDecoder(\n",
    "        latent_dim=latent_dim,\n",
    "        seq_len=max_length,\n",
    "        vocab_size=4,\n",
    "        dropout=0.1\n",
    "    )\n",
    "\n",
    "# Global decoder\n",
    "global_decoder = SequenceDecoder(\n",
    "    latent_dim=latent_dim,\n",
    "    seq_len=max_length,\n",
    "    vocab_size=4,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# Classifiers (uno por tax√≥n)\n",
    "classifiers_dict = {}\n",
    "print(f\"\\nüîß Creando classifiers con n√∫mero TOTAL de clases:\")\n",
    "for taxon in taxon_order:\n",
    "    # ‚úÖ CORRECTO: Usar total_classes (del dataset completo)\n",
    "    # ‚ùå INCORRECTO: n_classes = df_train[taxon].nunique()\n",
    "    n_classes = total_classes[taxon]\n",
    "    \n",
    "    classifiers_dict[taxon] = CosineClassifier(\n",
    "        latent_dim=latent_dim,\n",
    "        num_classes=n_classes,\n",
    "        scale=20.0  # ‚≠ê Ajustable si es necesario\n",
    "    )\n",
    "    print(f\"  {taxon:10s}: {n_classes:6d} clases\")\n",
    "\n",
    "# ‚≠ê CREAR MODELO JER√ÅRQUICO\n",
    "model = HierarchicalCombinedModelFixed(\n",
    "    dnabert=dnabert,\n",
    "    encoder=encoder,\n",
    "    decoders_dict=decoders_dict,\n",
    "    classifiers_dict=classifiers_dict,\n",
    "    global_decoder=global_decoder,\n",
    "    taxonomy_hierarchy=hierarchy  # ‚≠ê Aqu√≠ usas la jerarqu√≠a\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Modelo jer√°rquico creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06388570-02cc-47f2-ba6d-31cc55f33bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HierarchicalCombinedModelFixed(\n",
       "  (dnabert): DNABERTEmbedder(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(4096, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertUnpadAttention(\n",
       "              (self): BertUnpadSelfAttention(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (mlp): BertGatedLinearUnitMLP(\n",
       "              (gated_layers): Linear(in_features=768, out_features=6144, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): SimpleEmbeddingEncoder(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "      (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=384, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoders): ModuleDict(\n",
       "    (phylum): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (class): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (order): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (family): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (genus): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (species): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifiers): ModuleDict(\n",
       "    (phylum): CosineClassifier()\n",
       "    (class): CosineClassifier()\n",
       "    (order): CosineClassifier()\n",
       "    (family): CosineClassifier()\n",
       "    (genus): CosineClassifier()\n",
       "    (species): CosineClassifier()\n",
       "  )\n",
       "  (global_decoder): SequenceDecoder(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (6): GELU(approximate='none')\n",
       "      (7): Dropout(p=0.1, inplace=False)\n",
       "      (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "checkpoint_path = os.path.join(project_root, \"src\", \"data\", \"checkpointss\", \"final_model.pt\")\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a168e3a6-d236-4f76-b8f9-4b58bc82fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HierarchicalCombinedModelFixed(\n",
       "  (dnabert): DNABERTEmbedder(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(4096, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertUnpadAttention(\n",
       "              (self): BertUnpadSelfAttention(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (mlp): BertGatedLinearUnitMLP(\n",
       "              (gated_layers): Linear(in_features=768, out_features=6144, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): SimpleEmbeddingEncoder(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "      (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=384, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoders): ModuleDict(\n",
       "    (phylum): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (class): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (order): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (family): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (genus): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (species): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifiers): ModuleDict(\n",
       "    (phylum): CosineClassifier()\n",
       "    (class): CosineClassifier()\n",
       "    (order): CosineClassifier()\n",
       "    (family): CosineClassifier()\n",
       "    (genus): CosineClassifier()\n",
       "    (species): CosineClassifier()\n",
       "  )\n",
       "  (global_decoder): SequenceDecoder(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (6): GELU(approximate='none')\n",
       "      (7): Dropout(p=0.1, inplace=False)\n",
       "      (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c048f63-fdf2-48ab-b1e1-2e22b48792ca",
   "metadata": {},
   "source": [
    "# Cargamos el DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf2fef01-fee0-4572-a8a5-5a41f7aba201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Primero separar test (20%)\n",
    "df_temp, df_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['phylum']\n",
    ")\n",
    "\n",
    "# Luego separar train/val (80/20 del 80% restante = 64/16 del total)\n",
    "df_train, df_val = train_test_split(\n",
    "    df_temp, test_size=0.2, random_state=42, stratify=df_temp['phylum']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "262364d3-b75e-43bb-ba36-91073d468bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = MultiTaxaFastaDataset(\n",
    "    df_val.reset_index(drop=True),\n",
    "    max_length=max_length,\n",
    "    taxon_cols=taxon_order\n",
    ")\n",
    "\n",
    "test_dataset = MultiTaxaFastaDataset(\n",
    "    df_test.reset_index(drop=True),\n",
    "    max_length=max_length,\n",
    "    taxon_cols=taxon_order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ca5bc75-8bbb-4af4-a519-79b1fbd54361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_multitask(batch, taxon_cols=['phylum', 'class','order','family','genus','species'], max_length=900):\n",
    "    sequences, labels_dict_list, recon_targets_list, true_tokens_list = zip(*batch)\n",
    "\n",
    "    # Labels: dict de tensors\n",
    "    labels_dict = {taxon: torch.stack([d[taxon] for d in labels_dict_list]) for taxon in taxon_cols}\n",
    "\n",
    "    # Recon targets: dict de tensors\n",
    "    recon_targets_dict = {taxon: torch.stack([d[taxon] for d in recon_targets_list]) for taxon in taxon_cols}\n",
    "\n",
    "    # True tokens\n",
    "    true_tokens = torch.stack(true_tokens_list)\n",
    "\n",
    "    return sequences, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c40d611b-4890-4dc0-817a-517c02ab12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=lambda b: collate_multitask(b, taxon_cols=val_dataset.taxon_cols, max_length=val_dataset.max_length),\n",
    "    num_workers=6\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=lambda b: collate_multitask(b, taxon_cols=val_dataset.taxon_cols, max_length=val_dataset.max_length),\n",
    "    num_workers=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f0399b-a7df-4562-a017-709d42b763b7",
   "metadata": {},
   "source": [
    "# Algoritmo Genetico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e163ea9d-945e-410b-8bd0-aef4bfb4c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(sequences):\n",
    "    probs_by_rank = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(sequences)['logits']    \n",
    "        # predictions is a list of [rank0_output, rank1_output, rank2_output, ...]\n",
    "        # Each rank_output has shape [batch_size, num_classes_for_that_rank]\n",
    "            \n",
    "        for rank, rank_pred in predictions.items():\n",
    "            # Get probabilities for all sequences in this rank\n",
    "            probs = torch.softmax(rank_pred, dim=-1).cpu().numpy()\n",
    "            probs_by_rank.append(probs)\n",
    "        \n",
    "        return probs_by_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42c9dd81-cf7b-4164-a1dc-ee913f7861a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.genetics.genetic_algorithm_dna import GeneticAlgorithmDNA\n",
    "from src.genetics.dna_sequence_perturber import DNASequencePerturber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fef90b5-b19e-4c9f-bc59-2ceba0e466cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING GENETIC ALGORITHM EXPERIMENTS\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   1%|‚ñé                                                      | 176/30890 [06:19<18:24:38,  2.16s/it, fitness=4766.0737, entropy=23.8371, n_count=81, patience=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              4766.0737\n",
      "  Average Fitness:           2409.1543\n",
      "  Best Entropy Score:        23.8371\n",
      "  Best N Count:              81\n",
      "  Best N Count Penalty:      0.1013\n",
      "  Best Continuity Penalty:   1.2500\n",
      "\n",
      "{'sequence_length': 750, 'n_positions': [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546], 'fitness': np.float32(4766.0737), 'entropy_score': np.float32(23.837124), 'n_count_penalty': 0.10125, 'continuity_penalty': 1.250000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%|                                                        | 49/30890 [01:10<12:19:24,  1.44s/it, fitness=4766.0737, entropy=23.8371, n_count=81, patience=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              4766.0737\n",
      "  Average Fitness:           2507.4988\n",
      "  Best Entropy Score:        23.8371\n",
      "  Best N Count:              81\n",
      "  Best N Count Penalty:      0.1013\n",
      "  Best Continuity Penalty:   1.2500\n",
      "\n",
      "{'sequence_length': 750, 'n_positions': [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546], 'fitness': np.float32(4766.0737), 'entropy_score': np.float32(23.837124), 'n_count_penalty': 0.10125, 'continuity_penalty': 1.250000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%|                                                        | 24/30890 [00:33<12:05:15,  1.41s/it, fitness=4766.0737, entropy=23.8371, n_count=81, patience=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              4766.0737\n",
      "  Average Fitness:           2389.8394\n",
      "  Best Entropy Score:        23.8371\n",
      "  Best N Count:              81\n",
      "  Best N Count Penalty:      0.1013\n",
      "  Best Continuity Penalty:   1.2500\n",
      "\n",
      "{'sequence_length': 750, 'n_positions': [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546], 'fitness': np.float32(4766.0737), 'entropy_score': np.float32(23.837124), 'n_count_penalty': 0.10125, 'continuity_penalty': 1.250000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%|                                                        | 11/30890 [00:15<11:52:25,  1.38s/it, fitness=4766.0737, entropy=23.8371, n_count=81, patience=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              4766.0737\n",
      "  Average Fitness:           2469.0266\n",
      "  Best Entropy Score:        23.8371\n",
      "  Best N Count:              81\n",
      "  Best N Count Penalty:      0.1013\n",
      "  Best Continuity Penalty:   1.2500\n",
      "\n",
      "{'sequence_length': 750, 'n_positions': [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546], 'fitness': np.float32(4766.0737), 'entropy_score': np.float32(23.837124), 'n_count_penalty': 0.10125, 'continuity_penalty': 1.250000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%|                                                         | 5/30890 [00:08<14:20:39,  1.67s/it, fitness=4766.0737, entropy=23.8371, n_count=81, patience=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              4766.0737\n",
      "  Average Fitness:           2500.9438\n",
      "  Best Entropy Score:        23.8371\n",
      "  Best N Count:              81\n",
      "  Best N Count Penalty:      0.1013\n",
      "  Best Continuity Penalty:   1.2500\n",
      "\n",
      "{'sequence_length': 750, 'n_positions': [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546], 'fitness': np.float32(4766.0737), 'entropy_score': np.float32(23.837124), 'n_count_penalty': 0.10125, 'continuity_penalty': 1.250000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%|                                                         | 2/30890 [00:05<22:13:00,  2.59s/it, fitness=4766.0737, entropy=23.8371, n_count=81, patience=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              4766.0737\n",
      "  Average Fitness:           2343.2615\n",
      "  Best Entropy Score:        23.8371\n",
      "  Best N Count:              81\n",
      "  Best N Count Penalty:      0.1013\n",
      "  Best Continuity Penalty:   1.2500\n",
      "\n",
      "{'sequence_length': 750, 'n_positions': [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546], 'fitness': np.float32(4766.0737), 'entropy_score': np.float32(23.837124), 'n_count_penalty': 0.10125, 'continuity_penalty': 1.250000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%|                                                                                                                                | 0/30890 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              4766.0737\n",
      "  Average Fitness:           2660.5232\n",
      "  Best Entropy Score:        23.8371\n",
      "  Best N Count:              81\n",
      "  Best N Count Penalty:      0.1013\n",
      "  Best Continuity Penalty:   1.2500\n",
      "\n",
      "{'sequence_length': 750, 'n_positions': [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546], 'fitness': np.float32(4766.0737), 'entropy_score': np.float32(23.837124), 'n_count_penalty': 0.10125, 'continuity_penalty': 1.250000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%|                                                                                                                                | 0/30890 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              4766.0737\n",
      "  Average Fitness:           2314.7876\n",
      "  Best Entropy Score:        23.8371\n",
      "  Best N Count:              81\n",
      "  Best N Count Penalty:      0.1013\n",
      "  Best Continuity Penalty:   1.2500\n",
      "\n",
      "{'sequence_length': 750, 'n_positions': [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546], 'fitness': np.float32(4766.0737), 'entropy_score': np.float32(23.837124), 'n_count_penalty': 0.10125, 'continuity_penalty': 1.250000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%|                                                                                                                                | 0/30890 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              4766.0737\n",
      "  Average Fitness:           2318.4053\n",
      "  Best Entropy Score:        23.8371\n",
      "  Best N Count:              81\n",
      "  Best N Count Penalty:      0.1013\n",
      "  Best Continuity Penalty:   1.2500\n",
      "\n",
      "{'sequence_length': 750, 'n_positions': [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546], 'fitness': np.float32(4766.0737), 'entropy_score': np.float32(23.837124), 'n_count_penalty': 0.10125, 'continuity_penalty': 1.250000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%|                                                                                                                                | 0/30890 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              4766.0737\n",
      "  Average Fitness:           2452.3447\n",
      "  Best Entropy Score:        23.8371\n",
      "  Best N Count:              81\n",
      "  Best N Count Penalty:      0.1013\n",
      "  Best Continuity Penalty:   1.2500\n",
      "\n",
      "{'sequence_length': 750, 'n_positions': [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546], 'fitness': np.float32(4766.0737), 'entropy_score': np.float32(23.837124), 'n_count_penalty': 0.10125, 'continuity_penalty': 1.250000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "populations = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING GENETIC ALGORITHM EXPERIMENTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create GA\n",
    "ga = GeneticAlgorithmDNA(\n",
    "    classify,\n",
    "    [0],\n",
    "    population_size = 100,\n",
    "    \n",
    "    max_n_count = 400,\n",
    "    max_sequence_lengths = max_length,\n",
    "\n",
    "    entropy_weight=200,\n",
    "    n_penalty_weight = 0.5,\n",
    "    discontinuity_penalty_weight = 50,\n",
    "    \n",
    "    mutation_rate = 0.5,\n",
    "    crossover_rate = 0.7,\n",
    "    tournament_size = 4,\n",
    "    elitism_count = 3\n",
    ")\n",
    "\n",
    "for i in range(1):\n",
    "    # Run GA\n",
    "    best_solution, history, last_population = ga.run(\n",
    "        val_loader, \n",
    "        epochs = 10\n",
    "    )\n",
    "\n",
    "    populations.append(last_population)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba5f582-f770-4d29-b995-5beec6a6c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "from datetime import datetime\n",
    "\n",
    "def plot_population_n_heatmap(population, smooth_sigma=3):\n",
    "    \"\"\"\n",
    "    Given a population of individuals, each with n_positions,\n",
    "    plot a smoothed 1D heatmap showing the normalized frequency \n",
    "    of 'N' at each sequence position.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    population : list of dicts\n",
    "        Each dict must contain:\n",
    "        - 'sequence_length'\n",
    "        - 'n_positions' : list of indices where the individual places Ns\n",
    "    smooth_sigma : float\n",
    "        Gaussian smoothing strength for the 1D signal.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assume all individuals have same sequence length\n",
    "    seq_len = population[0].sequence_length\n",
    "    pop_size = len(population)\n",
    "\n",
    "    # Count Ns per position\n",
    "    freq = np.zeros(seq_len)\n",
    "\n",
    "    for indiv in population:\n",
    "        freq[indiv.n_positions] += 1\n",
    "\n",
    "    # Normalize to [0,1]\n",
    "    freq /= pop_size\n",
    "\n",
    "    # Smooth the curve\n",
    "    smooth_freq = gaussian_filter1d(freq, sigma=smooth_sigma)\n",
    "\n",
    "    # Plot heatmap-like bar\n",
    "    plt.figure(figsize=(14, 3))\n",
    "\n",
    "    plt.imshow(\n",
    "        smooth_freq[np.newaxis, :], \n",
    "        cmap='magma',\n",
    "        aspect='auto',\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "\n",
    "    plt.yticks([])  # 1D heatmap ‚Üí no y-axis needed\n",
    "    plt.xlabel(\"Sequence Position\")\n",
    "    plt.title(\"Smoothed N-Frequency Heatmap (Population-Level)\")\n",
    "\n",
    "    plt.colorbar(label=\"Normalized Frequency\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    date = datetime.now().strftime(\"%Y%m%d\")\n",
    "    plt.savefig(f\"population_n_heatmap_{date}.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return freq, smooth_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccda5ed-442c-40c6-8a07-67b85c51df6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for population in populations: \n",
    "    plot_population_n_heatmap(population)\n",
    "\n",
    "flattened_pop = []\n",
    "for population in populations:\n",
    "    flattened_pop.extend(population)\n",
    "\n",
    "freq, smooth_freq = plot_population_n_heatmap(flattened_pop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07fe013e-ac6d-4a49-bf47-e616f584504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p80 = np.percentile(smooth_freq, 80)\n",
    "\n",
    "a = (smooth_freq > p80)\n",
    "print((np.sum(a) / 750)*100)\n",
    "\n",
    "plt.figure(figsize=(14, 3))\n",
    "\n",
    "plt.imshow(\n",
    "    a[np.newaxis, :], \n",
    "    cmap='magma',\n",
    "    aspect='auto',\n",
    "    interpolation='nearest'\n",
    ")\n",
    "\n",
    "plt.yticks([])  # 1D heatmap ‚Üí no y-axis needed\n",
    "plt.xlabel(\"Sequence Position\")\n",
    "plt.title(\"Smoothed N-Frequency Heatmap (Population-Level)\")\n",
    "\n",
    "plt.colorbar(label=\"Normalized Frequency\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0541ee6b-5a3c-47c8-8664-1dd25db5f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p90 = np.percentile(smooth_freq, 80)\n",
    "important_zones = (smooth_freq > p90)\n",
    "n_positions = np.nonzero(important_zones)[0]\n",
    "best_perturber = DNASequencePerturber(len(smooth_freq), n_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45d01e1b-85a1-4b3a-b9d1-3d5c031c5b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   2%|‚ñà‚ñà                                                                                                | 801/38613 [02:07<1:39:56,  6.31it/s, accuracy=69.0075]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m phylo_label \u001b[38;5;241m=\u001b[39m labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphylum\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m perturbed_batch \u001b[38;5;241m=\u001b[39m [best_perturber\u001b[38;5;241m.\u001b[39mapply_to_sequence(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences]\n\u001b[0;32m---> 11\u001b[0m predicciones \u001b[38;5;241m=\u001b[39m \u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperturbed_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m phylo_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(predicciones[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     13\u001b[0m phylo_predicctions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(phylo_probs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m, in \u001b[0;36mclassify\u001b[0;34m(sequences)\u001b[0m\n\u001b[1;32m      2\u001b[0m probs_by_rank \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 5\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m]    \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# predictions is a list of [rank0_output, rank1_output, rank2_output, ...]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Each rank_output has shape [batch_size, num_classes_for_that_rank]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rank, rank_pred \u001b[38;5;129;01min\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# Get probabilities for all sequences in this rank\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/data/data3/junibg-ego/Modelo_leo_coi/src/combined_model/combined_model_embedding.py:250\u001b[0m, in \u001b[0;36mHierarchicalCombinedModelFixed.forward\u001b[0;34m(self, sequences, use_hierarchy, true_labels)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# DNABERT embeddings (congelado)\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 250\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnabert\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Encoder\u001b[39;00m\n\u001b[1;32m    253\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(emb)\n",
      "File \u001b[0;32m~/micromamba/envs/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/data/data3/junibg-ego/Modelo_leo_coi/src/encoders_model/DNABERT_Embedder.py:59\u001b[0m, in \u001b[0;36mDNABERTEmbedder.forward\u001b[0;34m(self, sequences)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Ensure we're in eval mode and not computing gradients\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# Tokenize sequences\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Maxima longitud de las secuencias de entrenamiento (VER QUE ONDA)\u001b[39;49;00m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# Move to same device as model\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/micromamba/envs/torch_env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3073\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3072\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3073\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3075\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/micromamba/envs/torch_env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3161\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3156\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3157\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3158\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3159\u001b[0m         )\n\u001b[1;32m   3160\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 3161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3163\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3180\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   3184\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3185\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3203\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3204\u001b[0m     )\n",
      "File \u001b[0;32m~/micromamba/envs/torch_env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3362\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3352\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3353\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3354\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3355\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3359\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3360\u001b[0m )\n\u001b[0;32m-> 3362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3364\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3380\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/torch_env/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:553\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m!=\u001b[39m split_special_tokens:\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m=\u001b[39m split_special_tokens\n\u001b[0;32m--> 553\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: tuple[\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;66;03m#                       list[dict[str, list[list[int]]]] or list[dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m#                       list[EncodingFast]\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    565\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[1;32m    567\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[1;32m    577\u001b[0m ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_acc = 0\n",
    "total = 0\n",
    "pbar = tqdm(test_loader, desc=\"Evolution\")\n",
    "for sequences, labels in pbar:\n",
    "\n",
    "    total += batch_size \n",
    "    \n",
    "    phylo_label = labels[\"phylum\"]\n",
    "    \n",
    "    perturbed_batch = [best_perturber.apply_to_sequence(seq) for seq in sequences]\n",
    "    predicciones = classify(perturbed_batch)\n",
    "    phylo_probs = torch.tensor(predicciones[0])\n",
    "    phylo_predicctions = torch.argmax(phylo_probs, dim=1)\n",
    "    acc = (phylo_predicctions == phylo_label).sum().item() \n",
    "    total_acc += acc\n",
    "\n",
    "    pbar.set_postfix({\n",
    "                    'accuracy': f'{(total_acc/total)*100:.4f}',\n",
    "                })\n",
    "\n",
    "print(total_acc / (len(test_loader) * batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch Env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
