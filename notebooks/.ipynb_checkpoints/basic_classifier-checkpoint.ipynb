{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1094c3c6-2f22-472d-aeca-3f94b742a549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/data3/junibg-ego/Modelo_leo_coi\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bea7ca3-7804-474c-a3d4-1489c925a1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿GPU disponible? True\n",
      "Número de GPUs: 2\n",
      "Nombre GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"¿GPU disponible? {torch.cuda.is_available()}\")\n",
    "print(f\"Número de GPUs: {torch.cuda.device_count()}\")\n",
    "print(f\"Nombre GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49aa6170-2f16-47bf-9ed1-2eca29f87e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e41276dc-8cbe-4305-b3ed-c57badbee5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.load_fastaDataset import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b61594b-2dcb-4bfe-b63e-8e8307166e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hierarchy_from_json(json_path):\n",
    "    \"\"\"Carga la jerarquía taxonómica desde JSON\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        hierarchy_raw = json.load(f)\n",
    "    \n",
    "    # Convertir claves string a int\n",
    "    hierarchy = {}\n",
    "    for child_taxon, parent_dict in hierarchy_raw.items():\n",
    "        hierarchy[child_taxon] = {}\n",
    "        for parent_key, children_list in parent_dict.items():\n",
    "            parent_int = int(float(parent_key))\n",
    "            children_int = [int(c) for c in children_list]\n",
    "            hierarchy[child_taxon][parent_int] = children_int\n",
    "    \n",
    "    print(\"✅ Jerarquía cargada desde JSON\")\n",
    "    for taxon, mapping in hierarchy.items():\n",
    "        n_parents = len(mapping)\n",
    "        n_children = sum(len(v) for v in mapping.values())\n",
    "        print(f\"  {taxon:10s}: {n_parents:4d} padres → {n_children:5d} hijos\")\n",
    "    \n",
    "    return hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8522d134-ccfb-4531-9c27-12b9b3a30c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Jerarquía cargada desde JSON\n",
      "  class     :   49 padres →   187 hijos\n",
      "  order     :  173 padres →   831 hijos\n",
      "  family    :  797 padres →  5446 hijos\n",
      "  genus     : 5393 padres → 50568 hijos\n",
      "  species   : 50510 padres → 205075 hijos\n"
     ]
    }
   ],
   "source": [
    "hierarchy_path = os.path.join(project_root, \"src\", \"data\", \"taxonomy_hierarchy_fixed_with_class.json\")\n",
    "hierarchy = load_hierarchy_from_json(hierarchy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13bdbd12-7690-4119-9ff7-c3010517aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = os.path.join(project_root, \"src\", \"data\", \"all_taxa_numeric.csv\")\n",
    "df = pd.read_csv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f15e5c6-57db-4a48-a06d-ae980f9fe31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  phylum    :     49 clases\n",
      "  class     :    173 clases\n",
      "  order     :    797 clases\n",
      "  family    :   5393 clases\n",
      "  genus     :  50510 clases\n",
      "  species   : 205075 clases\n"
     ]
    }
   ],
   "source": [
    "taxon_order = ['phylum', 'class','order', 'family', 'genus', 'species']\n",
    "total_classes = {}\n",
    "for taxon in taxon_order:\n",
    "    n_classes = df[taxon].nunique()\n",
    "    total_classes[taxon] = n_classes\n",
    "    print(f\"  {taxon:10s}: {n_classes:6d} clases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c4046f-8747-46a0-998d-dbb40d8cb7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 173, 797, 5393, 50510, 205075]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /data/data3/junibg-ego/Modelo_leo_coi/src/data/archives and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNAClassifier(\n",
      "  (embedder): DNABERTEmbedder(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(4096, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x BertLayer(\n",
      "            (attention): BertUnpadAttention(\n",
      "              (self): BertUnpadSelfAttention(\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (mlp): BertGatedLinearUnitMLP(\n",
      "              (gated_layers): Linear(in_features=768, out_features=6144, bias=False)\n",
      "              (act): GELU(approximate='none')\n",
      "              (wo): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (rank_classifiers_pre_process): ModuleList(\n",
      "    (0-5): 6 x Sequential(\n",
      "      (0): ResBlock(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (conv1): Conv1d(1, 768, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (bn2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(768, 1, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (rank_classifiers_end): ModuleList(\n",
      "    (0-5): 6 x Sequential(\n",
      "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (1): RankClassiferCosine(\n",
      "        (classifier): Sequential(\n",
      "          (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "          (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (5): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (6): GELU(approximate='none')\n",
      "          (7): Dropout(p=0.1, inplace=False)\n",
      "          (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (9): CosineClassifier()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from src.basic_classifier.build_classifier import *\n",
    "\n",
    "number_of_classes = []\n",
    "for class_name, num_classes in total_classes.items():\n",
    "    number_of_classes.append(num_classes)\n",
    "\n",
    "print(number_of_classes)\n",
    "\n",
    "model_configuration = get_model_config(number_of_classes, project_root)\n",
    "classifier = build_model(model_configuration)\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef7c3f49-dd3c-4dce-bcb9-92d6237903ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Primero separar test (20%)\n",
    "df_temp, df_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['phylum']\n",
    ")\n",
    "\n",
    "# Luego separar train/val (80/20 del 80% restante = 64/16 del total)\n",
    "df_train, df_val = train_test_split(\n",
    "    df_temp, test_size=0.2, random_state=42, stratify=df_temp['phylum']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "546e9631-fa9b-4928-a98c-40d8edee91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = MultiTaxaFastaDataset(\n",
    "    df_val.reset_index(drop=True),\n",
    "    max_length=750,\n",
    "    taxon_cols=taxon_order\n",
    ")\n",
    "\n",
    "training_dataset = MultiTaxaFastaDataset(\n",
    "    df_train.reset_index(drop=True),\n",
    "    max_length=750,\n",
    "    taxon_cols=taxon_order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "752e4196-d15b-4e0d-9cf8-9d369e235fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_multitask(batch, taxon_cols=['phylum', 'class','order','family','genus','species'], max_length=900):\n",
    "    sequences, labels_dict_list, recon_targets_list, true_tokens_list = zip(*batch)\n",
    "\n",
    "    # Labels: dict de tensors\n",
    "    labels_dict = {taxon: torch.stack([d[taxon] for d in labels_dict_list]) for taxon in taxon_cols}\n",
    "\n",
    "    # Recon targets: dict de tensors\n",
    "    recon_targets_dict = {taxon: torch.stack([d[taxon] for d in recon_targets_list]) for taxon in taxon_cols}\n",
    "\n",
    "    # True tokens\n",
    "    true_tokens = torch.stack(true_tokens_list)\n",
    "\n",
    "    return sequences, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "959f2e1d-c95b-4ff1-88d8-c641d0326391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.basic_classifier.train_classifier import train_basic_classifier\n",
    "\n",
    "training_config = {\n",
    "        \"batch_size\" : 16,\n",
    "        \"num_epochs\" : 15,\n",
    "        \"lr\" : 5e-4,\n",
    "        \"weight_decay\": 1e-4,  # Add regularization\n",
    "        \"patience\": 5,  # More patience for large class counts\n",
    "        \"label_smoothing\": 0.08,  # Add for better generalization\n",
    "        \"gradient_clip\": 1.0,  # Prevent gradient explosion\n",
    "        \"warmup_epochs\": 2,  # Gradual LR warmup\n",
    "        \"lr_schedule\": \"cosine\",  # Cosine annealing\n",
    "        \"accumulation_steps\": 2,  # Gradient accumulation for effective batch_size=128\n",
    "    }\n",
    "\n",
    "# Optimizer config\n",
    "optimizer_config = {\n",
    "    \"type\": \"AdamW\",\n",
    "    \"lr\": 5e-4,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"eps\": 1e-8\n",
    "}   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a90a5ac-8726-4fe3-9235-ef57f3cf026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=training_config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    collate_fn=lambda b: collate_multitask(b, taxon_cols=val_dataset.taxon_cols, max_length=val_dataset.max_length),\n",
    "    num_workers=6\n",
    ")\n",
    "\n",
    "training_loader = DataLoader(\n",
    "    training_dataset,\n",
    "    batch_size=training_config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=lambda b: collate_multitask(b, taxon_cols=val_dataset.taxon_cols, max_length=val_dataset.max_length),\n",
    "    num_workers=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c2bafdf-cda2-4365-b755-c76a422ed73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Starting training...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [1.46898676e-05 4.24142832e-05 7.06177153e-05 1.46783521e-04\n",
      " 1.90667467e-04 2.12816267e-04]\n",
      "          Top-1: 0.2917, Top-5: 0.4062\n",
      "          Rank Top-1: [0.875 0.625 0.25  0.    0.    0.   ], Rank Top-5: [1.     0.75   0.625  0.0625 0.     0.    ]\n",
      "  Val   - Loss: 0.0028, Rank Loss: [8.27700855e-05 2.19678925e-04 3.12766800e-04 5.84616064e-04\n",
      " 7.54985396e-04 8.36123969e-04]\n",
      "          Top-1: 0.2188, Top-5: 0.3021\n",
      "          Rank Top-1: [0.875  0.375  0.0625 0.     0.     0.    ], Rank Top-5: [0.9375 0.4375 0.375  0.0625 0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [1.80021078e-05 4.56371019e-05 8.20634202e-05 1.41837057e-04\n",
      " 1.87847042e-04 2.13746910e-04]\n",
      "          Top-1: 0.2500, Top-5: 0.3750\n",
      "          Rank Top-1: [0.875 0.5   0.125 0.    0.    0.   ], Rank Top-5: [1.   0.75 0.5  0.   0.   0.  ]\n",
      "  Val   - Loss: 0.0028, Rank Loss: [0.000128   0.00019858 0.00030489 0.00057946 0.00075319 0.00083469]\n",
      "          Top-1: 0.1667, Top-5: 0.3229\n",
      "          Rank Top-1: [0.4375 0.375  0.1875 0.     0.     0.    ], Rank Top-5: [0.9375 0.5625 0.375  0.0625 0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [3.05461011e-05 3.83575667e-05 6.35747463e-05 1.37458121e-04\n",
      " 1.90926987e-04 2.08955523e-04]\n",
      "          Top-1: 0.2292, Top-5: 0.4167\n",
      "          Rank Top-1: [0.375 0.75  0.25  0.    0.    0.   ], Rank Top-5: [0.9375 0.875  0.6875 0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0028, Rank Loss: [9.95775147e-05 1.94830970e-04 3.34486185e-04 5.74254943e-04\n",
      " 7.47431949e-04 8.32547614e-04]\n",
      "          Top-1: 0.1875, Top-5: 0.3125\n",
      "          Rank Top-1: [0.5625 0.375  0.1875 0.     0.     0.    ], Rank Top-5: [0.9375 0.5    0.375  0.0625 0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [2.27386954e-05 4.31874069e-05 8.81233506e-05 1.42116723e-04\n",
      " 1.83933566e-04 2.19875094e-04]\n",
      "          Top-1: 0.2500, Top-5: 0.3542\n",
      "          Rank Top-1: [0.8125 0.625  0.0625 0.     0.     0.    ], Rank Top-5: [0.9375 0.75   0.4375 0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0028, Rank Loss: [0.00014401 0.00019689 0.00030483 0.00057297 0.00073839 0.00083079]\n",
      "          Top-1: 0.1875, Top-5: 0.3229\n",
      "          Rank Top-1: [0.5625 0.375  0.1875 0.     0.     0.    ], Rank Top-5: [0.9375 0.625  0.375  0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [1.61002642e-05 3.32229305e-05 6.90416211e-05 1.41825001e-04\n",
      " 1.83904962e-04 2.13009256e-04]\n",
      "          Top-1: 0.2917, Top-5: 0.4062\n",
      "          Rank Top-1: [0.875 0.75  0.125 0.    0.    0.   ], Rank Top-5: [1.     0.8125 0.625  0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0028, Rank Loss: [0.0001544  0.00020954 0.00030752 0.00057121 0.00073391 0.00082723]\n",
      "          Top-1: 0.1771, Top-5: 0.3229\n",
      "          Rank Top-1: [0.5625 0.375  0.125  0.     0.     0.    ], Rank Top-5: [0.875  0.6875 0.375  0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [3.08509898e-05 5.08057102e-05 7.64946754e-05 1.45457593e-04\n",
      " 1.90362378e-04 2.16878676e-04]\n",
      "          Top-1: 0.2188, Top-5: 0.3542\n",
      "          Rank Top-1: [0.75   0.4375 0.125  0.     0.     0.    ], Rank Top-5: [0.8125 0.75   0.5625 0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0028, Rank Loss: [0.00013824 0.00020423 0.00031383 0.00056989 0.00073192 0.00082657]\n",
      "          Top-1: 0.1771, Top-5: 0.3333\n",
      "          Rank Top-1: [0.5625 0.375  0.125  0.     0.     0.    ], Rank Top-5: [0.9375 0.6875 0.375  0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [3.99185562e-05 3.14477290e-05 9.03443404e-05 1.42007941e-04\n",
      " 1.96540869e-04 2.12576043e-04]\n",
      "          Top-1: 0.1979, Top-5: 0.3333\n",
      "          Rank Top-1: [0.4375 0.6875 0.0625 0.     0.     0.    ], Rank Top-5: [0.875  0.875  0.1875 0.0625 0.     0.    ]\n",
      "  Val   - Loss: 0.0028, Rank Loss: [0.00011401 0.00021612 0.00032238 0.00056853 0.00073126 0.00082994]\n",
      "          Top-1: 0.1979, Top-5: 0.3229\n",
      "          Rank Top-1: [0.625  0.4375 0.125  0.     0.     0.    ], Rank Top-5: [0.9375 0.6875 0.3125 0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [3.86945867e-05 5.93720149e-05 9.03109742e-05 1.50916167e-04\n",
      " 1.84989662e-04 2.13868875e-04]\n",
      "          Top-1: 0.1562, Top-5: 0.2292\n",
      "          Rank Top-1: [0.5    0.4375 0.     0.     0.     0.    ], Rank Top-5: [0.6875 0.5    0.1875 0.     0.     0.    ]\n",
      "  Val   - Loss: 0.0028, Rank Loss: [0.00011245 0.00021746 0.00032657 0.00056858 0.00072849 0.00083243]\n",
      "          Top-1: 0.1979, Top-5: 0.2917\n",
      "          Rank Top-1: [0.8125 0.375  0.     0.     0.     0.    ], Rank Top-5: [0.9375 0.6875 0.125  0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [2.22539238e-05 4.81149301e-05 8.86925759e-05 1.42252580e-04\n",
      " 1.91674814e-04 2.12464575e-04]\n",
      "          Top-1: 0.2292, Top-5: 0.3542\n",
      "          Rank Top-1: [0.75   0.375  0.1875 0.0625 0.     0.    ], Rank Top-5: [1.     0.6875 0.375  0.0625 0.     0.    ]\n",
      "  Val   - Loss: 0.0028, Rank Loss: [0.00010217 0.00020979 0.00032828 0.00056775 0.00072648 0.00083483]\n",
      "          Top-1: 0.2188, Top-5: 0.3125\n",
      "          Rank Top-1: [0.8125 0.5    0.     0.     0.     0.    ], Rank Top-5: [0.9375 0.625  0.3125 0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [2.93261374e-05 3.66565903e-05 7.75575020e-05 1.42158293e-04\n",
      " 1.72052479e-04 2.15045655e-04]\n",
      "          Top-1: 0.2396, Top-5: 0.3750\n",
      "          Rank Top-1: [0.75   0.6875 0.     0.     0.     0.    ], Rank Top-5: [0.875  0.8125 0.5    0.0625 0.     0.    ]\n",
      "  Val   - Loss: 0.0028, Rank Loss: [9.21966035e-05 2.01976596e-04 3.26059952e-04 5.67122917e-04\n",
      " 7.26307739e-04 8.36716674e-04]\n",
      "          Top-1: 0.2083, Top-5: 0.3125\n",
      "          Rank Top-1: [0.8125 0.4375 0.     0.     0.     0.    ], Rank Top-5: [0.9375 0.625  0.3125 0.     0.     0.    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                 | 0/61780 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|                                                                                                                               | 0/15445 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [11/15]\n",
      "  Train - Loss: 0.0007, Rank Loss: [2.59860892e-05 3.95495786e-05 7.95586976e-05 1.45046608e-04\n",
      " 1.92561988e-04 2.14376416e-04]\n",
      "          Top-1: 0.2500, Top-5: 0.3542\n",
      "          Rank Top-1: [0.6875 0.6875 0.125  0.     0.     0.    ], Rank Top-5: [0.875 0.75  0.5   0.    0.    0.   ]\n",
      "  Val   - Loss: 0.0027, Rank Loss: [8.45839114e-05 1.98974776e-04 3.22381776e-04 5.65657364e-04\n",
      " 7.24915294e-04 8.38909970e-04]\n",
      "          Top-1: 0.1979, Top-5: 0.3229\n",
      "          Rank Top-1: [0.8125 0.375  0.     0.     0.     0.    ], Rank Top-5: [0.9375 0.625  0.375  0.     0.     0.    ]\n",
      "Early stopping.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m best_val_acc, best_model_state, history, last_improved \u001b[38;5;241m=\u001b[39m train_basic_classifier(classifier, training_loader, val_loader, training_config, optimizer_config)\n\u001b[1;32m     10\u001b[0m date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/best_model_ddp_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m best_model_train_metrics \u001b[38;5;241m=\u001b[39m history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][last_improved]\n\u001b[1;32m     14\u001b[0m best_model_val_metrics \u001b[38;5;241m=\u001b[39m history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m][last_improved]\n",
      "File \u001b[0;32m~/micromamba/envs/torch_env/lib/python3.10/site-packages/torch/serialization.py:966\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    963\u001b[0m     f \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(f)\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 966\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    967\u001b[0m         _save(\n\u001b[1;32m    968\u001b[0m             obj,\n\u001b[1;32m    969\u001b[0m             opened_zipfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    972\u001b[0m             _disable_byteorder_record,\n\u001b[1;32m    973\u001b[0m         )\n\u001b[1;32m    974\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/torch_env/lib/python3.10/site-packages/torch/serialization.py:828\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 828\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/torch_env/lib/python3.10/site-packages/torch/serialization.py:792\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    786\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\n\u001b[1;32m    787\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream, get_crc32_options(), _get_storage_alignment()\n\u001b[1;32m    788\u001b[0m         )\n\u001b[1;32m    789\u001b[0m     )\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m--> 792\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_crc32_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_storage_alignment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory models does not exist."
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "classifier.to(\"cuda\")\n",
    "\n",
    "max_length = model_configuration[\"config_embedder\"][\"max_length\"]\n",
    "best_val_acc, best_model_state, history, last_improved = train_basic_classifier(classifier, training_loader, val_loader, training_config, optimizer_config)\n",
    "\n",
    "date = datetime.now().strftime(\"%Y%m%d\")\n",
    "torch.save(best_model_state, f\"best_model_ddp_{date}.pt\")\n",
    "\n",
    "best_model_train_metrics = history[\"train\"][last_improved]\n",
    "best_model_val_metrics = history[\"val\"][last_improved]\n",
    "\n",
    "print(\"\\nBEST MODEL\")\n",
    "print(f\"  Train - Loss: {best_model_train_metrics['loss_avg']:.4f}, Rank Loss: {best_model_train_metrics['loss_rank_avg']}\")\n",
    "print(f\"          Top-1: {best_model_train_metrics['top1_acc']:.4f}, Top-5: {best_model_train_metrics['top5_acc']:.4f}\")\n",
    "print(f\"          Rank Top-1: {best_model_train_metrics['top1_rank_acc']}, Rank Top-5: {best_model_train_metrics['top5_rank_acc']}\")\n",
    "print(f\"  Val   - Loss: {best_model_val_metrics['loss_avg']:.4f}, Rank Loss: {best_model_val_metrics['loss_rank_avg']}\")\n",
    "print(f\"          Top-1: {best_model_val_metrics['top1_acc']:.4f}, Top-5: {best_model_val_metrics['top5_acc']:.4f}\")\n",
    "print(f\"          Rank Top-1: {best_model_val_metrics['top1_rank_acc']}, Rank Top-5: {best_model_val_metrics['top5_rank_acc']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch Env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
