{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d85016-c144-4477-a84e-893a9ffe5369",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc878647-50d9-4032-9df0-ef5f3a7f393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/data3/junibg-ego/Modelo_leo_coi\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d09de48-c800-4593-934e-35be9e68a25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬øGPU disponible? True\n",
      "N√∫mero de GPUs: 2\n",
      "Nombre GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"¬øGPU disponible? {torch.cuda.is_available()}\")\n",
    "print(f\"N√∫mero de GPUs: {torch.cuda.device_count()}\")\n",
    "print(f\"Nombre GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53085c88-4b09-476c-a880-252cfa5fdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Tus imports\n",
    "from src.combined_model.combined_model_embedding import *\n",
    "from src.combined_model.combined_models import *\n",
    "from src.decoders.decoder_simple import *\n",
    "from src.encoders_model.DNABERT_Embedder import *\n",
    "from src.encoders_model.embdeeding_encoders import *\n",
    "from src.encoders_model.simple_encoders import *\n",
    "from src.evaluators.linear_evaluator import *\n",
    "from src.decoders.sequence_decoder import *\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f6fe74-ed42-42cc-8071-39b1110dee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.encoders_model.simple_encoders import *\n",
    "from src.utils.load_fastaDataset import *\n",
    "from src.training.experimentRunner import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a0540b-2f1b-4835-b2af-af5a0fd105d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hierarchy_from_json(json_path):\n",
    "    \"\"\"Carga la jerarqu√≠a taxon√≥mica desde JSON\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        hierarchy_raw = json.load(f)\n",
    "    \n",
    "    # Convertir claves string a int\n",
    "    hierarchy = {}\n",
    "    for child_taxon, parent_dict in hierarchy_raw.items():\n",
    "        hierarchy[child_taxon] = {}\n",
    "        for parent_key, children_list in parent_dict.items():\n",
    "            parent_int = int(float(parent_key))\n",
    "            children_int = [int(c) for c in children_list]\n",
    "            hierarchy[child_taxon][parent_int] = children_int\n",
    "    \n",
    "    print(\"‚úÖ Jerarqu√≠a cargada desde JSON\")\n",
    "    for taxon, mapping in hierarchy.items():\n",
    "        n_parents = len(mapping)\n",
    "        n_children = sum(len(v) for v in mapping.values())\n",
    "        print(f\"  {taxon:10s}: {n_parents:4d} padres ‚Üí {n_children:5d} hijos\")\n",
    "    \n",
    "    return hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "763948cf-2509-449a-9a3a-7acea1040f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Jerarqu√≠a cargada desde JSON\n",
      "  class     :   49 padres ‚Üí   187 hijos\n",
      "  order     :  173 padres ‚Üí   831 hijos\n",
      "  family    :  797 padres ‚Üí  5446 hijos\n",
      "  genus     : 5393 padres ‚Üí 50568 hijos\n",
      "  species   : 50510 padres ‚Üí 205075 hijos\n"
     ]
    }
   ],
   "source": [
    "hierarchy_path = os.path.join(project_root, \"src\", \"data\", \"taxonomy_hierarchy_fixed_with_class.json\")\n",
    "hierarchy = load_hierarchy_from_json(hierarchy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ea34314-0a7a-4eca-9ccc-b8920d224aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = os.path.join(project_root, \"src\", \"data\", \"all_taxa_numeric.csv\")\n",
    "df = pd.read_csv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc3d09b-ef72-4697-aee2-07c26dd76a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  phylum    :     49 clases\n",
      "  class     :    173 clases\n",
      "  order     :    797 clases\n",
      "  family    :   5393 clases\n",
      "  genus     :  50510 clases\n",
      "  species   : 205075 clases\n"
     ]
    }
   ],
   "source": [
    "taxon_order = ['phylum', 'class','order', 'family', 'genus', 'species']\n",
    "total_classes = {}\n",
    "for taxon in taxon_order:\n",
    "    n_classes = df[taxon].nunique()\n",
    "    total_classes[taxon] = n_classes\n",
    "    print(f\"  {taxon:10s}: {n_classes:6d} clases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208bf5fc-697a-4e59-8a82-71a4bcc4eaa6",
   "metadata": {},
   "source": [
    "# Definimos Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8f3052b-4b55-458b-a11a-ff41b7561ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 750\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861d394-267b-49c7-94bf-154e2f483bb0",
   "metadata": {},
   "source": [
    "# Cargamos el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45ac734b-d0b9-44ed-bb8a-4238e996c93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Dispositivo: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /data/data3/junibg-ego/Modelo_leo_coi/src/data/archives and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creando classifiers con n√∫mero TOTAL de clases:\n",
      "  phylum    :     49 clases\n",
      "  class     :    173 clases\n",
      "  order     :    797 clases\n",
      "  family    :   5393 clases\n",
      "  genus     :  50510 clases\n",
      "  species   : 205075 clases\n",
      "‚úÖ Modelo jer√°rquico creado con m√°scaras suaves (no -inf)\n",
      "\n",
      "‚úÖ Modelo jer√°rquico creado\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üñ•Ô∏è  Dispositivo: {device}\")\n",
    "\n",
    "# DNABERT\n",
    "dnabert_path = os.path.join(project_root, \"src\", \"data\", \"archives\")\n",
    "dnabert = DNABERTEmbedder(\n",
    "    model_name=dnabert_path,\n",
    "    max_length=max_length,\n",
    "    device=device\n",
    ")\n",
    "embed_dim = dnabert.get_embedding_dim()\n",
    "\n",
    "# Encoder\n",
    "latent_dim = 256\n",
    "encoder = SimpleEmbeddingEncoder(\n",
    "    embed_dim=embed_dim,\n",
    "    latent_dim=latent_dim,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# Decoders (uno por tax√≥n)\n",
    "decoders_dict = {}\n",
    "for taxon in taxon_order:\n",
    "    decoders_dict[taxon] = SequenceDecoder(\n",
    "        latent_dim=latent_dim,\n",
    "        seq_len=max_length,\n",
    "        vocab_size=4,\n",
    "        dropout=0.1\n",
    "    )\n",
    "\n",
    "# Global decoder\n",
    "global_decoder = SequenceDecoder(\n",
    "    latent_dim=latent_dim,\n",
    "    seq_len=max_length,\n",
    "    vocab_size=4,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# Classifiers (uno por tax√≥n)\n",
    "classifiers_dict = {}\n",
    "print(f\"\\nüîß Creando classifiers con n√∫mero TOTAL de clases:\")\n",
    "for taxon in taxon_order:\n",
    "    # ‚úÖ CORRECTO: Usar total_classes (del dataset completo)\n",
    "    # ‚ùå INCORRECTO: n_classes = df_train[taxon].nunique()\n",
    "    n_classes = total_classes[taxon]\n",
    "    \n",
    "    classifiers_dict[taxon] = CosineClassifier(\n",
    "        latent_dim=latent_dim,\n",
    "        num_classes=n_classes,\n",
    "        scale=20.0  # ‚≠ê Ajustable si es necesario\n",
    "    )\n",
    "    print(f\"  {taxon:10s}: {n_classes:6d} clases\")\n",
    "\n",
    "# ‚≠ê CREAR MODELO JER√ÅRQUICO\n",
    "model = HierarchicalCombinedModelFixed(\n",
    "    dnabert=dnabert,\n",
    "    encoder=encoder,\n",
    "    decoders_dict=decoders_dict,\n",
    "    classifiers_dict=classifiers_dict,\n",
    "    global_decoder=global_decoder,\n",
    "    taxonomy_hierarchy=hierarchy  # ‚≠ê Aqu√≠ usas la jerarqu√≠a\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Modelo jer√°rquico creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06388570-02cc-47f2-ba6d-31cc55f33bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HierarchicalCombinedModelFixed(\n",
       "  (dnabert): DNABERTEmbedder(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(4096, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertUnpadAttention(\n",
       "              (self): BertUnpadSelfAttention(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (mlp): BertGatedLinearUnitMLP(\n",
       "              (gated_layers): Linear(in_features=768, out_features=6144, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): SimpleEmbeddingEncoder(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "      (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=384, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoders): ModuleDict(\n",
       "    (phylum): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (class): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (order): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (family): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (genus): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (species): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifiers): ModuleDict(\n",
       "    (phylum): CosineClassifier()\n",
       "    (class): CosineClassifier()\n",
       "    (order): CosineClassifier()\n",
       "    (family): CosineClassifier()\n",
       "    (genus): CosineClassifier()\n",
       "    (species): CosineClassifier()\n",
       "  )\n",
       "  (global_decoder): SequenceDecoder(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (6): GELU(approximate='none')\n",
       "      (7): Dropout(p=0.1, inplace=False)\n",
       "      (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "checkpoint_path = os.path.join(project_root, \"src\", \"data\", \"checkpointss\", \"final_model.pt\")\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a168e3a6-d236-4f76-b8f9-4b58bc82fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HierarchicalCombinedModelFixed(\n",
       "  (dnabert): DNABERTEmbedder(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(4096, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertUnpadAttention(\n",
       "              (self): BertUnpadSelfAttention(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (mlp): BertGatedLinearUnitMLP(\n",
       "              (gated_layers): Linear(in_features=768, out_features=6144, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): SimpleEmbeddingEncoder(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "      (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=384, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoders): ModuleDict(\n",
       "    (phylum): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (class): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (order): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (family): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (genus): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (species): SequenceDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifiers): ModuleDict(\n",
       "    (phylum): CosineClassifier()\n",
       "    (class): CosineClassifier()\n",
       "    (order): CosineClassifier()\n",
       "    (family): CosineClassifier()\n",
       "    (genus): CosineClassifier()\n",
       "    (species): CosineClassifier()\n",
       "  )\n",
       "  (global_decoder): SequenceDecoder(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (6): GELU(approximate='none')\n",
       "      (7): Dropout(p=0.1, inplace=False)\n",
       "      (8): Linear(in_features=512, out_features=3000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c048f63-fdf2-48ab-b1e1-2e22b48792ca",
   "metadata": {},
   "source": [
    "# Cargamos el DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf2fef01-fee0-4572-a8a5-5a41f7aba201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Primero separar test (20%)\n",
    "df_temp, df_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['phylum']\n",
    ")\n",
    "\n",
    "# Luego separar train/val (80/20 del 80% restante = 64/16 del total)\n",
    "df_train, df_val = train_test_split(\n",
    "    df_temp, test_size=0.2, random_state=42, stratify=df_temp['phylum']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "262364d3-b75e-43bb-ba36-91073d468bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = MultiTaxaFastaDataset(\n",
    "    df_val.reset_index(drop=True),\n",
    "    max_length=max_length,\n",
    "    taxon_cols=taxon_order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ca5bc75-8bbb-4af4-a519-79b1fbd54361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_multitask(batch, taxon_cols=['phylum', 'class','order','family','genus','species'], max_length=900):\n",
    "    sequences, labels_dict_list, recon_targets_list, true_tokens_list = zip(*batch)\n",
    "\n",
    "    # Labels: dict de tensors\n",
    "    labels_dict = {taxon: torch.stack([d[taxon] for d in labels_dict_list]) for taxon in taxon_cols}\n",
    "\n",
    "    # Recon targets: dict de tensors\n",
    "    recon_targets_dict = {taxon: torch.stack([d[taxon] for d in recon_targets_list]) for taxon in taxon_cols}\n",
    "\n",
    "    # True tokens\n",
    "    true_tokens = torch.stack(true_tokens_list)\n",
    "\n",
    "    return sequences, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c40d611b-4890-4dc0-817a-517c02ab12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=lambda b: collate_multitask(b, taxon_cols=val_dataset.taxon_cols, max_length=val_dataset.max_length),\n",
    "    num_workers=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f0399b-a7df-4562-a017-709d42b763b7",
   "metadata": {},
   "source": [
    "# Algoritmo Genetico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e163ea9d-945e-410b-8bd0-aef4bfb4c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(sequences):\n",
    "    probs_by_rank = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(sequences)['logits']    \n",
    "        # predictions is a list of [rank0_output, rank1_output, rank2_output, ...]\n",
    "        # Each rank_output has shape [batch_size, num_classes_for_that_rank]\n",
    "            \n",
    "        for rank, rank_pred in predictions.items():\n",
    "            # Get probabilities for all sequences in this rank\n",
    "            probs = torch.softmax(rank_pred, dim=-1).cpu().numpy()\n",
    "            probs_by_rank.append(probs)\n",
    "        \n",
    "        return probs_by_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fef90b5-b19e-4c9f-bc59-2ceba0e466cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING GENETIC ALGORITHM EXPERIMENTS\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   1%|‚ñè                                             | 155/30890 [05:51<19:22:01,  2.27s/it, fitness=324.8000, entropy=3.2618, n_count=78, patience=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              324.8000\n",
      "  Average Fitness:           228.9714\n",
      "  Best Entropy Score:        3.2618\n",
      "  Best N Count:              78\n",
      "  Best N Count Penalty:      0.0780\n",
      "  Best Continuity Penalty:   1.2987\n",
      "\n",
      "{'sequence_length': 900, 'n_positions': [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'fitness': np.float32(324.80002), 'entropy_score': np.float32(3.2617674), 'n_count_penalty': 0.078, 'continuity_penalty': 1.2987012987012991}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%| | 49/30890 [01:13<12:51:20,  1.50s/it, fitness=324.8000, entropy=3.2618, n_count=78, patience\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              324.8000\n",
      "  Average Fitness:           238.0164\n",
      "  Best Entropy Score:        3.2618\n",
      "  Best N Count:              78\n",
      "  Best N Count Penalty:      0.0780\n",
      "  Best Continuity Penalty:   1.2987\n",
      "\n",
      "{'sequence_length': 900, 'n_positions': [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'fitness': np.float32(324.80002), 'entropy_score': np.float32(3.2617674), 'n_count_penalty': 0.078, 'continuity_penalty': 1.2987012987012991}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%| | 24/30890 [00:33<11:53:01,  1.39s/it, fitness=324.8000, entropy=3.2618, n_count=78, patience\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              324.8000\n",
      "  Average Fitness:           218.9065\n",
      "  Best Entropy Score:        3.2618\n",
      "  Best N Count:              78\n",
      "  Best N Count Penalty:      0.0780\n",
      "  Best Continuity Penalty:   1.2987\n",
      "\n",
      "{'sequence_length': 900, 'n_positions': [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'fitness': np.float32(324.80002), 'entropy_score': np.float32(3.2617674), 'n_count_penalty': 0.078, 'continuity_penalty': 1.2987012987012991}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%| | 11/30890 [00:19<15:19:38,  1.79s/it, fitness=324.8000, entropy=3.2618, n_count=78, patience\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              324.8000\n",
      "  Average Fitness:           234.2146\n",
      "  Best Entropy Score:        3.2618\n",
      "  Best N Count:              78\n",
      "  Best N Count Penalty:      0.0780\n",
      "  Best Continuity Penalty:   1.2987\n",
      "\n",
      "{'sequence_length': 900, 'n_positions': [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'fitness': np.float32(324.80002), 'entropy_score': np.float32(3.2617674), 'n_count_penalty': 0.078, 'continuity_penalty': 1.2987012987012991}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%| | 5/30890 [00:08<14:56:59,  1.74s/it, fitness=324.8000, entropy=3.2618, n_count=78, patience=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              324.8000\n",
      "  Average Fitness:           238.4236\n",
      "  Best Entropy Score:        3.2618\n",
      "  Best N Count:              78\n",
      "  Best N Count Penalty:      0.0780\n",
      "  Best Continuity Penalty:   1.2987\n",
      "\n",
      "{'sequence_length': 900, 'n_positions': [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'fitness': np.float32(324.80002), 'entropy_score': np.float32(3.2617674), 'n_count_penalty': 0.078, 'continuity_penalty': 1.2987012987012991}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%| | 2/30890 [00:04<18:08:41,  2.11s/it, fitness=324.8000, entropy=3.2618, n_count=78, patience=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              324.8000\n",
      "  Average Fitness:           223.3361\n",
      "  Best Entropy Score:        3.2618\n",
      "  Best N Count:              78\n",
      "  Best N Count Penalty:      0.0780\n",
      "  Best Continuity Penalty:   1.2987\n",
      "\n",
      "{'sequence_length': 900, 'n_positions': [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'fitness': np.float32(324.80002), 'entropy_score': np.float32(3.2617674), 'n_count_penalty': 0.078, 'continuity_penalty': 1.2987012987012991}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%|                                                                    | 0/30890 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              324.8000\n",
      "  Average Fitness:           210.9681\n",
      "  Best Entropy Score:        3.2618\n",
      "  Best N Count:              78\n",
      "  Best N Count Penalty:      0.0780\n",
      "  Best Continuity Penalty:   1.2987\n",
      "\n",
      "{'sequence_length': 900, 'n_positions': [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'fitness': np.float32(324.80002), 'entropy_score': np.float32(3.2617674), 'n_count_penalty': 0.078, 'continuity_penalty': 1.2987012987012991}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%|                                                                    | 0/30890 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              324.8000\n",
      "  Average Fitness:           224.5624\n",
      "  Best Entropy Score:        3.2618\n",
      "  Best N Count:              78\n",
      "  Best N Count Penalty:      0.0780\n",
      "  Best Continuity Penalty:   1.2987\n",
      "\n",
      "{'sequence_length': 900, 'n_positions': [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'fitness': np.float32(324.80002), 'entropy_score': np.float32(3.2617674), 'n_count_penalty': 0.078, 'continuity_penalty': 1.2987012987012991}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%|                                                                    | 0/30890 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              324.8000\n",
      "  Average Fitness:           222.2233\n",
      "  Best Entropy Score:        3.2618\n",
      "  Best N Count:              78\n",
      "  Best N Count Penalty:      0.0780\n",
      "  Best Continuity Penalty:   1.2987\n",
      "\n",
      "{'sequence_length': 900, 'n_positions': [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'fitness': np.float32(324.80002), 'entropy_score': np.float32(3.2617674), 'n_count_penalty': 0.078, 'continuity_penalty': 1.2987012987012991}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution:   0%|                                                                    | 0/30890 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10/10]\n",
      "\n",
      "Genetic Algorithm Status\n",
      "  Best Fitness:              324.8000\n",
      "  Average Fitness:           213.7719\n",
      "  Best Entropy Score:        3.2618\n",
      "  Best N Count:              78\n",
      "  Best N Count Penalty:      0.0780\n",
      "  Best Continuity Penalty:   1.2987\n",
      "\n",
      "{'sequence_length': 900, 'n_positions': [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'fitness': np.float32(324.80002), 'entropy_score': np.float32(3.2617674), 'n_count_penalty': 0.078, 'continuity_penalty': 1.2987012987012991}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.genetics.genetic_algorithm_dna import GeneticAlgorithmDNA\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "populations = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING GENETIC ALGORITHM EXPERIMENTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create GA\n",
    "ga = GeneticAlgorithmDNA(\n",
    "    classify,\n",
    "    [0],\n",
    "    population_size = 100,\n",
    "    \n",
    "    max_n_count = 400,\n",
    "    max_sequence_lengths = max_length,\n",
    "    \n",
    "    n_penalty_weight = 0.5,\n",
    "    discontinuity_penalty_weight = 50,\n",
    "    \n",
    "    mutation_rate = 0.5,\n",
    "    crossover_rate = 0.7,\n",
    "    tournament_size = 4,\n",
    "    elitism_count = 3\n",
    ")\n",
    "\n",
    "for i in range(3):\n",
    "    # Run GA\n",
    "    best_solution, history, last_population = ga.run(\n",
    "        val_loader, \n",
    "        epochs = 10\n",
    "    )\n",
    "\n",
    "    populations.append(last_population)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ba5f582-f770-4d29-b995-5beec6a6c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def plot_population_n_heatmap(population, smooth_sigma=3):\n",
    "    \"\"\"\n",
    "    Given a population of individuals, each with n_positions,\n",
    "    plot a smoothed 1D heatmap showing the normalized frequency \n",
    "    of 'N' at each sequence position.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    population : list of dicts\n",
    "        Each dict must contain:\n",
    "        - 'sequence_length'\n",
    "        - 'n_positions' : list of indices where the individual places Ns\n",
    "    smooth_sigma : float\n",
    "        Gaussian smoothing strength for the 1D signal.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assume all individuals have same sequence length\n",
    "    seq_len = population[0].sequence_length\n",
    "    pop_size = len(population)\n",
    "\n",
    "    # Count Ns per position\n",
    "    freq = np.zeros(seq_len)\n",
    "\n",
    "    for indiv in population:\n",
    "        freq[indiv.n_positions] += 1\n",
    "\n",
    "    # Normalize to [0,1]\n",
    "    freq /= pop_size\n",
    "\n",
    "    # Smooth the curve\n",
    "    smooth_freq = gaussian_filter1d(freq, sigma=smooth_sigma)\n",
    "\n",
    "    # Plot heatmap-like bar\n",
    "    plt.figure(figsize=(14, 3))\n",
    "\n",
    "    plt.imshow(\n",
    "        smooth_freq[np.newaxis, :], \n",
    "        cmap='magma',\n",
    "        aspect='auto',\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "\n",
    "    plt.yticks([])  # 1D heatmap ‚Üí no y-axis needed\n",
    "    plt.xlabel(\"Sequence Position\")\n",
    "    plt.title(\"Smoothed N-Frequency Heatmap (Population-Level)\")\n",
    "\n",
    "    plt.colorbar(label=\"Normalized Frequency\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #plt.savefig(\"population_n_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return freq, smooth_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ccda5ed-442c-40c6-8a07-67b85c51df6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01,\n",
       "        0.01, 0.01, 0.02, 0.02, 0.02, 0.05, 0.05, 0.05, 0.05, 0.7 , 0.78,\n",
       "        0.78, 0.79, 0.8 , 0.81, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83,\n",
       "        0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83,\n",
       "        0.83, 0.83, 0.82, 0.82, 0.82, 0.81, 0.81, 0.81, 0.79, 0.79, 0.79,\n",
       "        0.79, 0.15, 0.11, 0.11, 0.08, 0.07, 0.06, 0.04, 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.03, 0.03, 0.03, 0.05, 0.05, 0.05, 0.05, 0.07, 0.78, 0.79,\n",
       "        0.79, 0.79, 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.81, 0.81, 0.81,\n",
       "        0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.8 ,\n",
       "        0.8 , 0.8 , 0.79, 0.79, 0.79, 0.79, 0.78, 0.1 , 0.08, 0.04, 0.04,\n",
       "        0.03, 0.03, 0.03, 0.03, 0.03, 0.02, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.03, 0.05,\n",
       "        0.07, 0.07, 0.07, 0.07, 0.77, 0.77, 0.76, 0.76, 0.76, 0.75, 0.76,\n",
       "        0.74, 0.74, 0.74, 0.75, 0.04, 0.03, 0.03, 0.03, 0.03, 0.03, 0.02,\n",
       "        0.02, 0.01, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "        0.01, 0.01, 0.01, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.01, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.01, 0.01,\n",
       "        0.01, 0.01, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]),\n",
       " array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.46113428e-07,\n",
       "        2.04706109e-06, 7.18813714e-06, 2.24074984e-05, 6.19961454e-05,\n",
       "        1.54546002e-04, 3.50632592e-04, 7.25023019e-04, 1.37457081e-03,\n",
       "        2.40545755e-03, 3.94487485e-03, 6.11942731e-03, 9.14276723e-03,\n",
       "        1.34622395e-02, 2.00146571e-02, 3.05635310e-02, 4.79828503e-02,\n",
       "        7.62081430e-02, 1.19524023e-01, 1.81069211e-01, 2.60976766e-01,\n",
       "        3.55111943e-01, 4.55393287e-01, 5.51916492e-01, 6.35974036e-01,\n",
       "        7.02454605e-01, 7.50534950e-01, 7.82676077e-01, 8.02831794e-01,\n",
       "        8.14892091e-01, 8.21876522e-01, 8.25812159e-01, 8.27956931e-01,\n",
       "        8.29070692e-01, 8.29612617e-01, 8.29848905e-01, 8.29945950e-01,\n",
       "        8.29981083e-01, 8.29988272e-01, 8.29976700e-01, 8.29938004e-01,\n",
       "        8.29845454e-01, 8.29649814e-01, 8.29277024e-01, 8.28632617e-01,\n",
       "        8.27616504e-01, 8.26115520e-01, 8.24031762e-01, 8.21199942e-01,\n",
       "        8.17246515e-01, 8.11334692e-01, 8.01821488e-01, 7.85967089e-01,\n",
       "        7.59973516e-01, 7.19679375e-01, 6.62005108e-01, 5.86731342e-01,\n",
       "        4.97674782e-01, 4.02339100e-01, 3.09875242e-01, 2.28252090e-01,\n",
       "        1.62078395e-01, 1.12066794e-01, 7.60697626e-02, 5.07804579e-02,\n",
       "        3.31162566e-02, 2.08247758e-02, 1.24364847e-02, 6.95476208e-03,\n",
       "        3.60032734e-03, 1.70930653e-03, 7.44620333e-04, 2.94292646e-04,\n",
       "        1.04714989e-04, 3.32927842e-05, 9.08047120e-06, 1.78445371e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.33834028e-06, 6.14118326e-06,\n",
       "        2.15644114e-05, 6.67763816e-05, 1.83941375e-04, 4.56449869e-04,\n",
       "        1.02592137e-03, 2.09758865e-03, 3.94742951e-03, 6.85155106e-03,\n",
       "        1.11054855e-02, 1.71028736e-02, 2.55927574e-02, 3.81019728e-02,\n",
       "        5.73464781e-02, 8.72577164e-02, 1.32213416e-01, 1.95369799e-01,\n",
       "        2.76630724e-01, 3.71360699e-01, 4.70882680e-01, 5.64884443e-01,\n",
       "        6.44653535e-01, 7.05506022e-01, 7.47333340e-01, 7.73383459e-01,\n",
       "        7.88282876e-01, 7.96358926e-01, 8.00784581e-01, 8.03471331e-01,\n",
       "        8.05364143e-01, 8.06828786e-01, 8.07963305e-01, 8.08779975e-01,\n",
       "        8.09316613e-01, 8.09610225e-01, 8.09698096e-01, 8.09590757e-01,\n",
       "        8.09258711e-01, 8.08607423e-01, 8.07511099e-01, 8.05746890e-01,\n",
       "        8.02883386e-01, 7.98025820e-01, 7.89442542e-01, 7.74217895e-01,\n",
       "        7.48261592e-01, 7.07052543e-01, 6.47235288e-01, 5.68597954e-01,\n",
       "        4.75395330e-01, 3.75991118e-01, 2.80623148e-01, 1.98250152e-01,\n",
       "        1.34041186e-01, 8.86236861e-02, 5.91025290e-02, 4.09618767e-02,\n",
       "        2.98138044e-02, 2.24019599e-02, 1.68288112e-02, 1.22910240e-02,\n",
       "        8.63886120e-03, 5.98049940e-03, 4.43514809e-03, 3.99899331e-03,\n",
       "        4.57893172e-03, 6.01363878e-03, 8.13020158e-03, 1.08242856e-02,\n",
       "        1.40908686e-02, 1.81447177e-02, 2.35415150e-02, 3.13625500e-02,\n",
       "        4.34533900e-02, 6.26221411e-02, 9.25455097e-02, 1.37058061e-01,\n",
       "        1.98699220e-01, 2.76943171e-01, 3.67049987e-01, 4.60580640e-01,\n",
       "        5.47566498e-01, 6.19410710e-01, 6.70903549e-01, 7.00349116e-01,\n",
       "        7.08059886e-01, 6.94502805e-01, 6.59479930e-01, 6.02936027e-01,\n",
       "        5.26815878e-01, 4.36584334e-01, 3.41097695e-01, 2.50537809e-01,\n",
       "        1.73404770e-01, 1.14240947e-01, 7.30912438e-02, 4.67587332e-02,\n",
       "        3.07857715e-02, 2.11124533e-02, 1.48822396e-02, 1.04779408e-02,\n",
       "        7.15833395e-03, 4.64379999e-03, 2.81897726e-03, 1.59293048e-03,\n",
       "        8.28252001e-04, 3.94470088e-04, 1.71366311e-04, 6.75833349e-05,\n",
       "        2.40084460e-05, 7.63425057e-06, 2.04706109e-06, 4.46113428e-07,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.46113428e-07, 2.04706109e-06,\n",
       "        7.18813714e-06, 2.19613849e-05, 5.99490843e-05, 1.47357865e-04,\n",
       "        3.27332867e-04, 6.58932751e-04, 1.20520242e-03, 2.01019347e-03,\n",
       "        3.06990934e-03, 4.31311592e-03, 5.60497361e-03, 6.77554466e-03,\n",
       "        7.66042660e-03, 8.13541872e-03, 8.13541872e-03, 7.66042660e-03,\n",
       "        6.77554466e-03, 5.60497361e-03, 4.31311592e-03, 3.06990934e-03,\n",
       "        2.01019347e-03, 1.20520242e-03, 6.58932751e-04, 3.27332867e-04,\n",
       "        1.47357865e-04, 5.99490843e-05, 2.19613849e-05, 7.18813714e-06,\n",
       "        2.04706109e-06, 4.46113428e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.46113428e-07, 2.04706109e-06, 7.18813714e-06, 2.19613849e-05,\n",
       "        5.99490843e-05, 1.47357865e-04, 3.27332867e-04, 6.58932751e-04,\n",
       "        1.20564853e-03, 2.01179442e-03, 3.07505041e-03, 4.32788917e-03,\n",
       "        5.64296131e-03, 6.86295344e-03, 7.84040160e-03, 8.46701860e-03,\n",
       "        8.68213450e-03, 8.46701860e-03, 7.84040160e-03, 6.86295344e-03,\n",
       "        5.64296131e-03, 4.32788917e-03, 3.07505041e-03, 2.01179442e-03,\n",
       "        1.20564853e-03, 6.58932751e-04, 3.27332867e-04, 1.47357865e-04,\n",
       "        5.99490843e-05, 2.19613849e-05, 7.18813714e-06, 2.04706109e-06,\n",
       "        4.46113428e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.46113428e-07,\n",
       "        2.04706109e-06, 6.74202372e-06, 1.99143238e-05, 5.27609472e-05,\n",
       "        1.25396480e-04, 2.67383782e-04, 5.11574886e-04, 8.78315667e-04,\n",
       "        1.35330778e-03, 1.87144894e-03, 2.32283677e-03, 2.58782522e-03,\n",
       "        2.58782522e-03, 2.32283677e-03, 1.87144894e-03, 1.35330778e-03,\n",
       "        8.78315667e-04, 5.11574886e-04, 2.67383782e-04, 1.25396480e-04,\n",
       "        5.27609472e-05, 1.99143238e-05, 6.74202372e-06, 2.04706109e-06,\n",
       "        4.46113428e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.46113428e-07, 1.60094766e-06, 5.14107606e-06, 1.47732478e-05,\n",
       "        3.79876994e-05, 8.74087805e-05, 1.79975002e-04, 3.31599884e-04,\n",
       "        5.46715782e-04, 8.06591999e-04, 1.06485694e-03, 1.25797983e-03,\n",
       "        1.32984539e-03, 1.25797983e-03, 1.06485694e-03, 8.06591999e-04,\n",
       "        5.46715782e-04, 3.31599884e-04, 1.79975002e-04, 8.74087805e-05,\n",
       "        3.79876994e-05, 1.47732478e-05, 5.14107606e-06, 1.60094766e-06,\n",
       "        4.46113428e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.46113428e-07,\n",
       "        2.04706109e-06, 7.18813714e-06, 2.19613849e-05, 5.99490843e-05,\n",
       "        1.47357865e-04, 3.27332867e-04, 6.58486637e-04, 1.20360147e-03,\n",
       "        2.00505240e-03, 3.05513609e-03, 4.27512822e-03, 5.51756483e-03,\n",
       "        6.59556966e-03, 7.32882672e-03, 7.58870293e-03, 7.32882672e-03,\n",
       "        6.59556966e-03, 5.51756483e-03, 4.27512822e-03, 3.05513609e-03,\n",
       "        2.00505240e-03, 1.20360147e-03, 6.58486637e-04, 3.27332867e-04,\n",
       "        1.47357865e-04, 5.99490843e-05, 2.19613849e-05, 7.18813714e-06,\n",
       "        2.04706109e-06, 4.46113428e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_population_n_heatmap(last_population)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch Env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
